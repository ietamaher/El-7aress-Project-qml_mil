// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: riva/proto/riva_asr.proto

#include "riva/proto/riva_asr.pb.h"

#include <algorithm>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
#include "google/protobuf/generated_message_tctable_impl.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace nvidia {
namespace riva {
namespace asr {

inline constexpr WordInfo::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : word_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        start_time_{0},
        end_time_{0},
        confidence_{0},
        speaker_tag_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR WordInfo::WordInfo(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct WordInfoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR WordInfoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~WordInfoDefaultTypeInternal() {}
  union {
    WordInfo _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 WordInfoDefaultTypeInternal _WordInfo_default_instance_;

inline constexpr SpeechContext::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : phrases_{},
        boost_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechContext::SpeechContext(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct SpeechContextDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechContextDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechContextDefaultTypeInternal() {}
  union {
    SpeechContext _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechContextDefaultTypeInternal _SpeechContext_default_instance_;

inline constexpr SpeakerDiarizationConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : enable_speaker_diarization_{false},
        max_speaker_count_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeakerDiarizationConfig::SpeakerDiarizationConfig(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct SpeakerDiarizationConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeakerDiarizationConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeakerDiarizationConfigDefaultTypeInternal() {}
  union {
    SpeakerDiarizationConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeakerDiarizationConfigDefaultTypeInternal _SpeakerDiarizationConfig_default_instance_;
      template <typename>
PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse(::_pbi::ConstantInitialized) {}
struct RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUseDefaultTypeInternal() {}
  union {
    RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUseDefaultTypeInternal _RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse_default_instance_;

inline constexpr RivaSpeechRecognitionConfigRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : model_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigRequest::RivaSpeechRecognitionConfigRequest(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RivaSpeechRecognitionConfigRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RivaSpeechRecognitionConfigRequestDefaultTypeInternal() {}
  union {
    RivaSpeechRecognitionConfigRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RivaSpeechRecognitionConfigRequestDefaultTypeInternal _RivaSpeechRecognitionConfigRequest_default_instance_;
      template <typename>
PROTOBUF_CONSTEXPR RecognitionConfig_CustomConfigurationEntry_DoNotUse::RecognitionConfig_CustomConfigurationEntry_DoNotUse(::_pbi::ConstantInitialized) {}
struct RecognitionConfig_CustomConfigurationEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionConfig_CustomConfigurationEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionConfig_CustomConfigurationEntry_DoNotUseDefaultTypeInternal() {}
  union {
    RecognitionConfig_CustomConfigurationEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionConfig_CustomConfigurationEntry_DoNotUseDefaultTypeInternal _RecognitionConfig_CustomConfigurationEntry_DoNotUse_default_instance_;

inline constexpr PipelineStates::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : vad_probabilities_{},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR PipelineStates::PipelineStates(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct PipelineStatesDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PipelineStatesDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~PipelineStatesDefaultTypeInternal() {}
  union {
    PipelineStates _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PipelineStatesDefaultTypeInternal _PipelineStates_default_instance_;

inline constexpr EndpointingConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        start_history_{0},
        start_threshold_{0},
        stop_history_{0},
        stop_threshold_{0},
        stop_history_eou_{0},
        stop_threshold_eou_{0} {}

template <typename>
PROTOBUF_CONSTEXPR EndpointingConfig::EndpointingConfig(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct EndpointingConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR EndpointingConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~EndpointingConfigDefaultTypeInternal() {}
  union {
    EndpointingConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 EndpointingConfigDefaultTypeInternal _EndpointingConfig_default_instance_;

inline constexpr SpeechRecognitionAlternative::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : words_{},
        language_code_{},
        transcript_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        confidence_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionAlternative::SpeechRecognitionAlternative(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct SpeechRecognitionAlternativeDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionAlternativeDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionAlternativeDefaultTypeInternal() {}
  union {
    SpeechRecognitionAlternative _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionAlternativeDefaultTypeInternal _SpeechRecognitionAlternative_default_instance_;

inline constexpr RivaSpeechRecognitionConfigResponse_Config::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : parameters_{},
        model_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponse_Config::RivaSpeechRecognitionConfigResponse_Config(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RivaSpeechRecognitionConfigResponse_ConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponse_ConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RivaSpeechRecognitionConfigResponse_ConfigDefaultTypeInternal() {}
  union {
    RivaSpeechRecognitionConfigResponse_Config _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RivaSpeechRecognitionConfigResponse_ConfigDefaultTypeInternal _RivaSpeechRecognitionConfigResponse_Config_default_instance_;

inline constexpr RecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        speech_contexts_{},
        custom_configuration_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        model_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        diarization_config_{nullptr},
        endpointing_config_{nullptr},
        encoding_{static_cast< ::nvidia::riva::AudioEncoding >(0)},
        sample_rate_hertz_{0},
        max_alternatives_{0},
        audio_channel_count_{0},
        profanity_filter_{false},
        enable_word_time_offsets_{false},
        enable_automatic_punctuation_{false},
        enable_separate_recognition_per_channel_{false},
        verbatim_transcripts_{false} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionConfig::RecognitionConfig(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionConfigDefaultTypeInternal() {}
  union {
    RecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionConfigDefaultTypeInternal _RecognitionConfig_default_instance_;

inline constexpr StreamingRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        alternatives_{},
        pipeline_states_{nullptr},
        is_final_{false},
        stability_{0},
        channel_tag_{0},
        audio_processed_{0} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionResult::StreamingRecognitionResult(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct StreamingRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionResultDefaultTypeInternal() {}
  union {
    StreamingRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionResultDefaultTypeInternal _StreamingRecognitionResult_default_instance_;

inline constexpr StreamingRecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        interim_results_{false} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionConfig::StreamingRecognitionConfig(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct StreamingRecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionConfigDefaultTypeInternal() {}
  union {
    StreamingRecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionConfigDefaultTypeInternal _StreamingRecognitionConfig_default_instance_;

inline constexpr SpeechRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : alternatives_{},
        channel_tag_{0},
        audio_processed_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionResult::SpeechRecognitionResult(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct SpeechRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionResultDefaultTypeInternal() {}
  union {
    SpeechRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionResultDefaultTypeInternal _SpeechRecognitionResult_default_instance_;

inline constexpr RivaSpeechRecognitionConfigResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : model_config_{},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponse::RivaSpeechRecognitionConfigResponse(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RivaSpeechRecognitionConfigResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RivaSpeechRecognitionConfigResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RivaSpeechRecognitionConfigResponseDefaultTypeInternal() {}
  union {
    RivaSpeechRecognitionConfigResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RivaSpeechRecognitionConfigResponseDefaultTypeInternal _RivaSpeechRecognitionConfigResponse_default_instance_;

inline constexpr RecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        audio_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        config_{nullptr},
        id_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeRequest::RecognizeRequest(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeRequestDefaultTypeInternal() {}
  union {
    RecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeRequestDefaultTypeInternal _RecognizeRequest_default_instance_;

inline constexpr StreamingRecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        id_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeResponse::StreamingRecognizeResponse(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct StreamingRecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeResponseDefaultTypeInternal() {}
  union {
    StreamingRecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeResponseDefaultTypeInternal _StreamingRecognizeResponse_default_instance_;

inline constexpr StreamingRecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        id_{nullptr},
        streaming_request_{},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeRequest::StreamingRecognizeRequest(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct StreamingRecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeRequestDefaultTypeInternal() {}
  union {
    StreamingRecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeRequestDefaultTypeInternal _StreamingRecognizeRequest_default_instance_;

inline constexpr RecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        id_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeResponse::RecognizeResponse(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct RecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeResponseDefaultTypeInternal() {}
  union {
    RecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeResponseDefaultTypeInternal _RecognizeResponse_default_instance_;
}  // namespace asr
}  // namespace riva
}  // namespace nvidia
static ::_pb::Metadata file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[19];
static constexpr const ::_pb::EnumDescriptor**
    file_level_enum_descriptors_riva_2fproto_2friva_5fasr_2eproto = nullptr;
static constexpr const ::_pb::ServiceDescriptor**
    file_level_service_descriptors_riva_2fproto_2friva_5fasr_2eproto = nullptr;
const ::uint32_t TableStruct_riva_2fproto_2friva_5fasr_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(
    protodesc_cold) = {
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigRequest, _impl_.model_name_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse, _has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse, key_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse, value_),
    0,
    1,
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config, _impl_.model_name_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config, _impl_.parameters_),
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse, _impl_.model_config_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeRequest, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeRequest, _impl_.config_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeRequest, _impl_.audio_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeRequest, _impl_.id_),
    0,
    ~0u,
    1,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _impl_._oneof_case_[0]),
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    ::_pbi::kInvalidFieldOffsetTag,
    ::_pbi::kInvalidFieldOffsetTag,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _impl_.id_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _impl_.streaming_request_),
    ~0u,
    ~0u,
    0,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.start_history_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.start_threshold_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.stop_history_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.stop_threshold_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.stop_history_eou_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::EndpointingConfig, _impl_.stop_threshold_eou_),
    0,
    1,
    2,
    3,
    4,
    5,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig_CustomConfigurationEntry_DoNotUse, _has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig_CustomConfigurationEntry_DoNotUse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig_CustomConfigurationEntry_DoNotUse, key_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig_CustomConfigurationEntry_DoNotUse, value_),
    0,
    1,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.encoding_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.sample_rate_hertz_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.language_code_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.max_alternatives_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.profanity_filter_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.speech_contexts_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.audio_channel_count_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.enable_word_time_offsets_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.enable_automatic_punctuation_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.enable_separate_recognition_per_channel_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.model_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.verbatim_transcripts_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.diarization_config_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.custom_configuration_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognitionConfig, _impl_.endpointing_config_),
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    0,
    ~0u,
    1,
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionConfig, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionConfig, _impl_.config_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionConfig, _impl_.interim_results_),
    0,
    ~0u,
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeakerDiarizationConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeakerDiarizationConfig, _impl_.max_speaker_count_),
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechContext, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechContext, _impl_.phrases_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechContext, _impl_.boost_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeResponse, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeResponse, _impl_.results_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::RecognizeResponse, _impl_.id_),
    ~0u,
    0,
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionResult, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionResult, _impl_.alternatives_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionResult, _impl_.channel_tag_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionResult, _impl_.audio_processed_),
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionAlternative, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionAlternative, _impl_.transcript_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionAlternative, _impl_.confidence_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionAlternative, _impl_.words_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::SpeechRecognitionAlternative, _impl_.language_code_),
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.start_time_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.end_time_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.word_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.confidence_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.speaker_tag_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::WordInfo, _impl_.language_code_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeResponse, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeResponse, _impl_.results_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeResponse, _impl_.id_),
    ~0u,
    0,
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::PipelineStates, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::PipelineStates, _impl_.vad_probabilities_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_._has_bits_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.alternatives_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.is_final_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.stability_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.channel_tag_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.audio_processed_),
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognitionResult, _impl_.pipeline_states_),
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    ~0u,
    0,
};

static const ::_pbi::MigrationSchema
    schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
        {0, -1, -1, sizeof(::nvidia::riva::asr::RivaSpeechRecognitionConfigRequest)},
        {9, 19, -1, sizeof(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse)},
        {21, -1, -1, sizeof(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config)},
        {31, -1, -1, sizeof(::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse)},
        {40, 51, -1, sizeof(::nvidia::riva::asr::RecognizeRequest)},
        {54, 66, -1, sizeof(::nvidia::riva::asr::StreamingRecognizeRequest)},
        {69, 83, -1, sizeof(::nvidia::riva::asr::EndpointingConfig)},
        {89, 99, -1, sizeof(::nvidia::riva::asr::RecognitionConfig_CustomConfigurationEntry_DoNotUse)},
        {101, 124, -1, sizeof(::nvidia::riva::asr::RecognitionConfig)},
        {139, 149, -1, sizeof(::nvidia::riva::asr::StreamingRecognitionConfig)},
        {151, -1, -1, sizeof(::nvidia::riva::asr::SpeakerDiarizationConfig)},
        {161, -1, -1, sizeof(::nvidia::riva::asr::SpeechContext)},
        {171, 181, -1, sizeof(::nvidia::riva::asr::RecognizeResponse)},
        {183, -1, -1, sizeof(::nvidia::riva::asr::SpeechRecognitionResult)},
        {194, -1, -1, sizeof(::nvidia::riva::asr::SpeechRecognitionAlternative)},
        {206, -1, -1, sizeof(::nvidia::riva::asr::WordInfo)},
        {220, 230, -1, sizeof(::nvidia::riva::asr::StreamingRecognizeResponse)},
        {232, -1, -1, sizeof(::nvidia::riva::asr::PipelineStates)},
        {241, 255, -1, sizeof(::nvidia::riva::asr::StreamingRecognitionResult)},
};

static const ::_pb::Message* const file_default_instances[] = {
    &::nvidia::riva::asr::_RivaSpeechRecognitionConfigRequest_default_instance_._instance,
    &::nvidia::riva::asr::_RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse_default_instance_._instance,
    &::nvidia::riva::asr::_RivaSpeechRecognitionConfigResponse_Config_default_instance_._instance,
    &::nvidia::riva::asr::_RivaSpeechRecognitionConfigResponse_default_instance_._instance,
    &::nvidia::riva::asr::_RecognizeRequest_default_instance_._instance,
    &::nvidia::riva::asr::_StreamingRecognizeRequest_default_instance_._instance,
    &::nvidia::riva::asr::_EndpointingConfig_default_instance_._instance,
    &::nvidia::riva::asr::_RecognitionConfig_CustomConfigurationEntry_DoNotUse_default_instance_._instance,
    &::nvidia::riva::asr::_RecognitionConfig_default_instance_._instance,
    &::nvidia::riva::asr::_StreamingRecognitionConfig_default_instance_._instance,
    &::nvidia::riva::asr::_SpeakerDiarizationConfig_default_instance_._instance,
    &::nvidia::riva::asr::_SpeechContext_default_instance_._instance,
    &::nvidia::riva::asr::_RecognizeResponse_default_instance_._instance,
    &::nvidia::riva::asr::_SpeechRecognitionResult_default_instance_._instance,
    &::nvidia::riva::asr::_SpeechRecognitionAlternative_default_instance_._instance,
    &::nvidia::riva::asr::_WordInfo_default_instance_._instance,
    &::nvidia::riva::asr::_StreamingRecognizeResponse_default_instance_._instance,
    &::nvidia::riva::asr::_PipelineStates_default_instance_._instance,
    &::nvidia::riva::asr::_StreamingRecognitionResult_default_instance_._instance,
};
const char descriptor_table_protodef_riva_2fproto_2friva_5fasr_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
    "\n\031riva/proto/riva_asr.proto\022\017nvidia.riva"
    ".asr\032\033riva/proto/riva_audio.proto\032\034riva/"
    "proto/riva_common.proto\"8\n\"RivaSpeechRec"
    "ognitionConfigRequest\022\022\n\nmodel_name\030\001 \001("
    "\t\"\253\002\n#RivaSpeechRecognitionConfigRespons"
    "e\022Q\n\014model_config\030\001 \003(\0132;.nvidia.riva.as"
    "r.RivaSpeechRecognitionConfigResponse.Co"
    "nfig\032\260\001\n\006Config\022\022\n\nmodel_name\030\001 \001(\t\022_\n\np"
    "arameters\030\002 \003(\0132K.nvidia.riva.asr.RivaSp"
    "eechRecognitionConfigResponse.Config.Par"
    "ametersEntry\0321\n\017ParametersEntry\022\013\n\003key\030\001"
    " \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\"y\n\020RecognizeRequ"
    "est\0222\n\006config\030\001 \001(\0132\".nvidia.riva.asr.Re"
    "cognitionConfig\022\r\n\005audio\030\002 \001(\014\022\"\n\002id\030d \001"
    "(\0132\026.nvidia.riva.RequestId\"\266\001\n\031Streaming"
    "RecognizeRequest\022G\n\020streaming_config\030\001 \001"
    "(\0132+.nvidia.riva.asr.StreamingRecognitio"
    "nConfigH\000\022\027\n\raudio_content\030\002 \001(\014H\000\022\"\n\002id"
    "\030d \001(\0132\026.nvidia.riva.RequestIdB\023\n\021stream"
    "ing_request\"\273\002\n\021EndpointingConfig\022\032\n\rsta"
    "rt_history\030\001 \001(\005H\000\210\001\001\022\034\n\017start_threshold"
    "\030\002 \001(\002H\001\210\001\001\022\031\n\014stop_history\030\003 \001(\005H\002\210\001\001\022\033"
    "\n\016stop_threshold\030\004 \001(\002H\003\210\001\001\022\035\n\020stop_hist"
    "ory_eou\030\005 \001(\005H\004\210\001\001\022\037\n\022stop_threshold_eou"
    "\030\006 \001(\002H\005\210\001\001B\020\n\016_start_historyB\022\n\020_start_"
    "thresholdB\017\n\r_stop_historyB\021\n\017_stop_thre"
    "sholdB\023\n\021_stop_history_eouB\025\n\023_stop_thre"
    "shold_eou\"\335\005\n\021RecognitionConfig\022,\n\010encod"
    "ing\030\001 \001(\0162\032.nvidia.riva.AudioEncoding\022\031\n"
    "\021sample_rate_hertz\030\002 \001(\005\022\025\n\rlanguage_cod"
    "e\030\003 \001(\t\022\030\n\020max_alternatives\030\004 \001(\005\022\030\n\020pro"
    "fanity_filter\030\005 \001(\010\0227\n\017speech_contexts\030\006"
    " \003(\0132\036.nvidia.riva.asr.SpeechContext\022\033\n\023"
    "audio_channel_count\030\007 \001(\005\022 \n\030enable_word"
    "_time_offsets\030\010 \001(\010\022$\n\034enable_automatic_"
    "punctuation\030\013 \001(\010\022/\n\'enable_separate_rec"
    "ognition_per_channel\030\014 \001(\010\022\r\n\005model\030\r \001("
    "\t\022\034\n\024verbatim_transcripts\030\016 \001(\010\022E\n\022diari"
    "zation_config\030\023 \001(\0132).nvidia.riva.asr.Sp"
    "eakerDiarizationConfig\022Y\n\024custom_configu"
    "ration\030\030 \003(\0132;.nvidia.riva.asr.Recogniti"
    "onConfig.CustomConfigurationEntry\022C\n\022end"
    "pointing_config\030\031 \001(\0132\".nvidia.riva.asr."
    "EndpointingConfigH\000\210\001\001\032:\n\030CustomConfigur"
    "ationEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\002"
    "8\001B\025\n\023_endpointing_config\"i\n\032StreamingRe"
    "cognitionConfig\0222\n\006config\030\001 \001(\0132\".nvidia"
    ".riva.asr.RecognitionConfig\022\027\n\017interim_r"
    "esults\030\002 \001(\010\"Y\n\030SpeakerDiarizationConfig"
    "\022\"\n\032enable_speaker_diarization\030\001 \001(\010\022\031\n\021"
    "max_speaker_count\030\002 \001(\005\"/\n\rSpeechContext"
    "\022\017\n\007phrases\030\001 \003(\t\022\r\n\005boost\030\004 \001(\002\"r\n\021Reco"
    "gnizeResponse\0229\n\007results\030\001 \003(\0132(.nvidia."
    "riva.asr.SpeechRecognitionResult\022\"\n\002id\030d"
    " \001(\0132\026.nvidia.riva.RequestId\"\214\001\n\027SpeechR"
    "ecognitionResult\022C\n\014alternatives\030\001 \003(\0132-"
    ".nvidia.riva.asr.SpeechRecognitionAltern"
    "ative\022\023\n\013channel_tag\030\002 \001(\005\022\027\n\017audio_proc"
    "essed\030\003 \001(\002\"\207\001\n\034SpeechRecognitionAlterna"
    "tive\022\022\n\ntranscript\030\001 \001(\t\022\022\n\nconfidence\030\002"
    " \001(\002\022(\n\005words\030\003 \003(\0132\031.nvidia.riva.asr.Wo"
    "rdInfo\022\025\n\rlanguage_code\030\004 \003(\t\"~\n\010WordInf"
    "o\022\022\n\nstart_time\030\001 \001(\005\022\020\n\010end_time\030\002 \001(\005\022"
    "\014\n\004word\030\003 \001(\t\022\022\n\nconfidence\030\004 \001(\002\022\023\n\013spe"
    "aker_tag\030\005 \001(\005\022\025\n\rlanguage_code\030\006 \001(\t\"~\n"
    "\032StreamingRecognizeResponse\022<\n\007results\030\001"
    " \003(\0132+.nvidia.riva.asr.StreamingRecognit"
    "ionResult\022\"\n\002id\030d \001(\0132\026.nvidia.riva.Requ"
    "estId\"+\n\016PipelineStates\022\031\n\021vad_probabili"
    "ties\030\001 \003(\002\"\207\002\n\032StreamingRecognitionResul"
    "t\022C\n\014alternatives\030\001 \003(\0132-.nvidia.riva.as"
    "r.SpeechRecognitionAlternative\022\020\n\010is_fin"
    "al\030\002 \001(\010\022\021\n\tstability\030\003 \001(\002\022\023\n\013channel_t"
    "ag\030\005 \001(\005\022\027\n\017audio_processed\030\006 \001(\002\022=\n\017pip"
    "eline_states\030\007 \001(\0132\037.nvidia.riva.asr.Pip"
    "elineStatesH\000\210\001\001B\022\n\020_pipeline_states2\362\002\n"
    "\025RivaSpeechRecognition\022T\n\tRecognize\022!.nv"
    "idia.riva.asr.RecognizeRequest\032\".nvidia."
    "riva.asr.RecognizeResponse\"\000\022s\n\022Streamin"
    "gRecognize\022*.nvidia.riva.asr.StreamingRe"
    "cognizeRequest\032+.nvidia.riva.asr.Streami"
    "ngRecognizeResponse\"\000(\0010\001\022\215\001\n\036GetRivaSpe"
    "echRecognitionConfig\0223.nvidia.riva.asr.R"
    "ivaSpeechRecognitionConfigRequest\0324.nvid"
    "ia.riva.asr.RivaSpeechRecognitionConfigR"
    "esponse\"\000B\033Z\026nvidia.com/riva_speech\370\001\001b\006"
    "proto3"
};
static const ::_pbi::DescriptorTable* const descriptor_table_riva_2fproto_2friva_5fasr_2eproto_deps[2] =
    {
        &::descriptor_table_riva_2fproto_2friva_5faudio_2eproto,
        &::descriptor_table_riva_2fproto_2friva_5fcommon_2eproto,
};
static ::absl::once_flag descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_riva_2fproto_2friva_5fasr_2eproto = {
    false,
    false,
    3446,
    descriptor_table_protodef_riva_2fproto_2friva_5fasr_2eproto,
    "riva/proto/riva_asr.proto",
    &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
    descriptor_table_riva_2fproto_2friva_5fasr_2eproto_deps,
    2,
    19,
    schemas,
    file_default_instances,
    TableStruct_riva_2fproto_2friva_5fasr_2eproto::offsets,
    file_level_metadata_riva_2fproto_2friva_5fasr_2eproto,
    file_level_enum_descriptors_riva_2fproto_2friva_5fasr_2eproto,
    file_level_service_descriptors_riva_2fproto_2friva_5fasr_2eproto,
};

// This function exists to be marked as weak.
// It can significantly speed up compilation by breaking up LLVM's SCC
// in the .pb.cc translation units. Large translation units see a
// reduction of more than 35% of walltime for optimized builds. Without
// the weak attribute all the messages in the file, including all the
// vtables and everything they use become part of the same SCC through
// a cycle like:
// GetMetadata -> descriptor table -> default instances ->
//   vtables -> GetMetadata
// By adding a weak function here we break the connection from the
// individual vtables back into the descriptor table.
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter() {
  return &descriptor_table_riva_2fproto_2friva_5fasr_2eproto;
}
// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2
static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_riva_2fproto_2friva_5fasr_2eproto(&descriptor_table_riva_2fproto_2friva_5fasr_2eproto);
namespace nvidia {
namespace riva {
namespace asr {
// ===================================================================

class RivaSpeechRecognitionConfigRequest::_Internal {
 public:
};

RivaSpeechRecognitionConfigRequest::RivaSpeechRecognitionConfigRequest(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : model_name_(arena, from.model_name_),
        _cached_size_{0} {}

RivaSpeechRecognitionConfigRequest::RivaSpeechRecognitionConfigRequest(
    ::google::protobuf::Arena* arena,
    const RivaSpeechRecognitionConfigRequest& from)
    : ::google::protobuf::Message(arena) {
  RivaSpeechRecognitionConfigRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : model_name_(arena),
        _cached_size_{0} {}

inline void RivaSpeechRecognitionConfigRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
RivaSpeechRecognitionConfigRequest::~RivaSpeechRecognitionConfigRequest() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RivaSpeechRecognitionConfigRequest::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.model_name_.Destroy();
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RivaSpeechRecognitionConfigRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.model_name_.ClearToEmpty();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RivaSpeechRecognitionConfigRequest::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 0, 69, 2> RivaSpeechRecognitionConfigRequest::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_RivaSpeechRecognitionConfigRequest_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // string model_name = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigRequest, _impl_.model_name_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string model_name = 1;
    {PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigRequest, _impl_.model_name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\62\12\0\0\0\0\0\0"
    "nvidia.riva.asr.RivaSpeechRecognitionConfigRequest"
    "model_name"
  }},
};

::uint8_t* RivaSpeechRecognitionConfigRequest::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    const std::string& _s = this->_internal_model_name();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigRequest.model_name");
    target = stream->WriteStringMaybeAliased(1, _s, target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  return target;
}

::size_t RivaSpeechRecognitionConfigRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_model_name());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RivaSpeechRecognitionConfigRequest::_class_data_ = {
    RivaSpeechRecognitionConfigRequest::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RivaSpeechRecognitionConfigRequest::GetClassData() const {
  return &_class_data_;
}

void RivaSpeechRecognitionConfigRequest::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RivaSpeechRecognitionConfigRequest*>(&to_msg);
  auto& from = static_cast<const RivaSpeechRecognitionConfigRequest&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_model_name().empty()) {
    _this->_internal_set_model_name(from._internal_model_name());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RivaSpeechRecognitionConfigRequest::CopyFrom(const RivaSpeechRecognitionConfigRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RivaSpeechRecognitionConfigRequest::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RivaSpeechRecognitionConfigRequest::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RivaSpeechRecognitionConfigRequest::InternalSwap(RivaSpeechRecognitionConfigRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.model_name_, &other->_impl_.model_name_, arena);
}

::google::protobuf::Metadata RivaSpeechRecognitionConfigRequest::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[0]);
}
// ===================================================================

RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse() {}
RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse::RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse(::google::protobuf::Arena* arena)
    : SuperType(arena) {}
::google::protobuf::Metadata RivaSpeechRecognitionConfigResponse_Config_ParametersEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[1]);
}
// ===================================================================

class RivaSpeechRecognitionConfigResponse_Config::_Internal {
 public:
};

RivaSpeechRecognitionConfigResponse_Config::RivaSpeechRecognitionConfigResponse_Config(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigResponse_Config::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : parameters_{visibility, arena, from.parameters_},
        model_name_(arena, from.model_name_),
        _cached_size_{0} {}

RivaSpeechRecognitionConfigResponse_Config::RivaSpeechRecognitionConfigResponse_Config(
    ::google::protobuf::Arena* arena,
    const RivaSpeechRecognitionConfigResponse_Config& from)
    : ::google::protobuf::Message(arena) {
  RivaSpeechRecognitionConfigResponse_Config* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigResponse_Config::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : parameters_{visibility, arena},
        model_name_(arena),
        _cached_size_{0} {}

inline void RivaSpeechRecognitionConfigResponse_Config::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
RivaSpeechRecognitionConfigResponse_Config::~RivaSpeechRecognitionConfigResponse_Config() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RivaSpeechRecognitionConfigResponse_Config::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.model_name_.Destroy();
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RivaSpeechRecognitionConfigResponse_Config::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.parameters_.Clear();
  _impl_.model_name_.ClearToEmpty();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RivaSpeechRecognitionConfigResponse_Config::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 2, 1, 87, 2> RivaSpeechRecognitionConfigResponse_Config::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_RivaSpeechRecognitionConfigResponse_Config_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // string model_name = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigResponse_Config, _impl_.model_name_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string model_name = 1;
    {PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigResponse_Config, _impl_.model_name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // map<string, string> parameters = 2;
    {PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigResponse_Config, _impl_.parameters_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
  }}, {{
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(RivaSpeechRecognitionConfigResponse_Config()._impl_.parameters_)>(
        1, 0, 0, 9,
        9)},
  }}, {{
    "\72\12\12\0\0\0\0\0"
    "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config"
    "model_name"
    "parameters"
  }},
};

::uint8_t* RivaSpeechRecognitionConfigResponse_Config::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    const std::string& _s = this->_internal_model_name();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config.model_name");
    target = stream->WriteStringMaybeAliased(1, _s, target);
  }

  // map<string, string> parameters = 2;
  if (!_internal_parameters().empty()) {
    using MapType = ::google::protobuf::Map<std::string, std::string>;
    using WireHelper = _pbi::MapEntryFuncs<std::string, std::string,
                                   _pbi::WireFormatLite::TYPE_STRING,
                                   _pbi::WireFormatLite::TYPE_STRING>;
    const auto& field = _internal_parameters();

    if (stream->IsSerializationDeterministic() && field.size() > 1) {
      for (const auto& entry : ::google::protobuf::internal::MapSorterPtr<MapType>(field)) {
        target = WireHelper::InternalSerialize(
            2, entry.first, entry.second, target, stream);
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config.parameters");
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config.parameters");
      }
    } else {
      for (const auto& entry : field) {
        target = WireHelper::InternalSerialize(
            2, entry.first, entry.second, target, stream);
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config.parameters");
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config.parameters");
      }
    }
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  return target;
}

::size_t RivaSpeechRecognitionConfigResponse_Config::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // map<string, string> parameters = 2;
  total_size += 1 * ::google::protobuf::internal::FromIntSize(_internal_parameters_size());
  for (const auto& entry : _internal_parameters()) {
    total_size += _pbi::MapEntryFuncs<std::string, std::string,
                                   _pbi::WireFormatLite::TYPE_STRING,
                                   _pbi::WireFormatLite::TYPE_STRING>::ByteSizeLong(entry.first, entry.second);
  }
  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_model_name());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RivaSpeechRecognitionConfigResponse_Config::_class_data_ = {
    RivaSpeechRecognitionConfigResponse_Config::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RivaSpeechRecognitionConfigResponse_Config::GetClassData() const {
  return &_class_data_;
}

void RivaSpeechRecognitionConfigResponse_Config::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RivaSpeechRecognitionConfigResponse_Config*>(&to_msg);
  auto& from = static_cast<const RivaSpeechRecognitionConfigResponse_Config&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.parameters_.MergeFrom(from._impl_.parameters_);
  if (!from._internal_model_name().empty()) {
    _this->_internal_set_model_name(from._internal_model_name());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RivaSpeechRecognitionConfigResponse_Config::CopyFrom(const RivaSpeechRecognitionConfigResponse_Config& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RivaSpeechRecognitionConfigResponse_Config::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RivaSpeechRecognitionConfigResponse_Config::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RivaSpeechRecognitionConfigResponse_Config::InternalSwap(RivaSpeechRecognitionConfigResponse_Config* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.parameters_.InternalSwap(&other->_impl_.parameters_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.model_name_, &other->_impl_.model_name_, arena);
}

::google::protobuf::Metadata RivaSpeechRecognitionConfigResponse_Config::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[2]);
}
// ===================================================================

class RivaSpeechRecognitionConfigResponse::_Internal {
 public:
};

RivaSpeechRecognitionConfigResponse::RivaSpeechRecognitionConfigResponse(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : model_config_{visibility, arena, from.model_config_},
        _cached_size_{0} {}

RivaSpeechRecognitionConfigResponse::RivaSpeechRecognitionConfigResponse(
    ::google::protobuf::Arena* arena,
    const RivaSpeechRecognitionConfigResponse& from)
    : ::google::protobuf::Message(arena) {
  RivaSpeechRecognitionConfigResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
}
inline PROTOBUF_NDEBUG_INLINE RivaSpeechRecognitionConfigResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : model_config_{visibility, arena},
        _cached_size_{0} {}

inline void RivaSpeechRecognitionConfigResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
RivaSpeechRecognitionConfigResponse::~RivaSpeechRecognitionConfigResponse() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RivaSpeechRecognitionConfigResponse::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RivaSpeechRecognitionConfigResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.model_config_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RivaSpeechRecognitionConfigResponse::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 1, 0, 2> RivaSpeechRecognitionConfigResponse::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_RivaSpeechRecognitionConfigResponse_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // repeated .nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config model_config = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigResponse, _impl_.model_config_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config model_config = 1;
    {PROTOBUF_FIELD_OFFSET(RivaSpeechRecognitionConfigResponse, _impl_.model_config_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::RivaSpeechRecognitionConfigResponse_Config>()},
  }}, {{
  }},
};

::uint8_t* RivaSpeechRecognitionConfigResponse::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config model_config = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_model_config_size()); i < n; i++) {
    const auto& repfield = this->_internal_model_config().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  return target;
}

::size_t RivaSpeechRecognitionConfigResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.RivaSpeechRecognitionConfigResponse.Config model_config = 1;
  total_size += 1UL * this->_internal_model_config_size();
  for (const auto& msg : this->_internal_model_config()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RivaSpeechRecognitionConfigResponse::_class_data_ = {
    RivaSpeechRecognitionConfigResponse::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RivaSpeechRecognitionConfigResponse::GetClassData() const {
  return &_class_data_;
}

void RivaSpeechRecognitionConfigResponse::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RivaSpeechRecognitionConfigResponse*>(&to_msg);
  auto& from = static_cast<const RivaSpeechRecognitionConfigResponse&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_model_config()->MergeFrom(
      from._internal_model_config());
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RivaSpeechRecognitionConfigResponse::CopyFrom(const RivaSpeechRecognitionConfigResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RivaSpeechRecognitionConfigResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RivaSpeechRecognitionConfigResponse::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RivaSpeechRecognitionConfigResponse::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RivaSpeechRecognitionConfigResponse::InternalSwap(RivaSpeechRecognitionConfigResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.model_config_.InternalSwap(&other->_impl_.model_config_);
}

::google::protobuf::Metadata RivaSpeechRecognitionConfigResponse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[3]);
}
// ===================================================================

class RecognizeRequest::_Internal {
 public:
  using HasBits = decltype(std::declval<RecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_);
  static const ::nvidia::riva::asr::RecognitionConfig& config(const RecognizeRequest* msg);
  static void set_has_config(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static const ::nvidia::riva::RequestId& id(const RecognizeRequest* msg);
  static void set_has_id(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

const ::nvidia::riva::asr::RecognitionConfig& RecognizeRequest::_Internal::config(const RecognizeRequest* msg) {
  return *msg->_impl_.config_;
}
const ::nvidia::riva::RequestId& RecognizeRequest::_Internal::id(const RecognizeRequest* msg) {
  return *msg->_impl_.id_;
}
void RecognizeRequest::clear_id() {
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  if (_impl_.id_ != nullptr) _impl_.id_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
RecognizeRequest::RecognizeRequest(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        audio_(arena, from.audio_) {}

RecognizeRequest::RecognizeRequest(
    ::google::protobuf::Arena* arena,
    const RecognizeRequest& from)
    : ::google::protobuf::Message(arena) {
  RecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::asr::RecognitionConfig>(arena, *from._impl_.config_)
                : nullptr;
  _impl_.id_ = (cached_has_bits & 0x00000002u)
                ? CreateMaybeMessage<::nvidia::riva::RequestId>(arena, *from._impl_.id_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        audio_(arena) {}

inline void RecognizeRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, id_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::id_));
}
RecognizeRequest::~RecognizeRequest() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RecognizeRequest)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RecognizeRequest::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.audio_.Destroy();
  delete _impl_.config_;
  delete _impl_.id_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RecognizeRequest)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.audio_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.id_ != nullptr);
      _impl_.id_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RecognizeRequest::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 2, 0, 7> RecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    100, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_RecognizeRequest_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // .nvidia.riva.RequestId id = 100;
    {::_pbi::TcParser::FastMtS2,
     {1698, 1, 1, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.id_)}},
    // .nvidia.riva.asr.RecognitionConfig config = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)}},
    // bytes audio = 2;
    {::_pbi::TcParser::FastBS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    100, 0, 1,
    65534, 2,
    65535, 65535
  }}, {{
    // .nvidia.riva.asr.RecognitionConfig config = 1;
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bytes audio = 2;
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBytes | ::_fl::kRepAString)},
    // .nvidia.riva.RequestId id = 100;
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.id_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::RecognitionConfig>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::RequestId>()},
  }}, {{
  }},
};

::uint8_t* RecognizeRequest::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RecognizeRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.asr.RecognitionConfig config = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, _Internal::config(this),
        _Internal::config(this).GetCachedSize(), target, stream);
  }

  // bytes audio = 2;
  if (!this->_internal_audio().empty()) {
    const std::string& _s = this->_internal_audio();
    target = stream->WriteBytesMaybeAliased(2, _s, target);
  }

  // .nvidia.riva.RequestId id = 100;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        100, _Internal::id(this),
        _Internal::id(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RecognizeRequest)
  return target;
}

::size_t RecognizeRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RecognizeRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // bytes audio = 2;
  if (!this->_internal_audio().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                    this->_internal_audio());
  }

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    // .nvidia.riva.asr.RecognitionConfig config = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size +=
          1 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.config_);
    }

    // .nvidia.riva.RequestId id = 100;
    if (cached_has_bits & 0x00000002u) {
      total_size +=
          2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.id_);
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RecognizeRequest::_class_data_ = {
    RecognizeRequest::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RecognizeRequest::GetClassData() const {
  return &_class_data_;
}

void RecognizeRequest::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RecognizeRequest*>(&to_msg);
  auto& from = static_cast<const RecognizeRequest&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_audio().empty()) {
    _this->_internal_set_audio(from._internal_audio());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      _this->_internal_mutable_config()->::nvidia::riva::asr::RecognitionConfig::MergeFrom(
          from._internal_config());
    }
    if (cached_has_bits & 0x00000002u) {
      _this->_internal_mutable_id()->::nvidia::riva::RequestId::MergeFrom(
          from._internal_id());
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeRequest::CopyFrom(const RecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RecognizeRequest::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RecognizeRequest::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RecognizeRequest::InternalSwap(RecognizeRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.audio_, &other->_impl_.audio_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.id_)
      + sizeof(RecognizeRequest::_impl_.id_)
      - PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata RecognizeRequest::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[4]);
}
// ===================================================================

class StreamingRecognizeRequest::_Internal {
 public:
  using HasBits = decltype(std::declval<StreamingRecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_._has_bits_);
  static constexpr ::int32_t kOneofCaseOffset =
    PROTOBUF_FIELD_OFFSET(::nvidia::riva::asr::StreamingRecognizeRequest, _impl_._oneof_case_);
  static const ::nvidia::riva::asr::StreamingRecognitionConfig& streaming_config(const StreamingRecognizeRequest* msg);
  static const ::nvidia::riva::RequestId& id(const StreamingRecognizeRequest* msg);
  static void set_has_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

const ::nvidia::riva::asr::StreamingRecognitionConfig& StreamingRecognizeRequest::_Internal::streaming_config(const StreamingRecognizeRequest* msg) {
  return *msg->_impl_.streaming_request_.streaming_config_;
}
const ::nvidia::riva::RequestId& StreamingRecognizeRequest::_Internal::id(const StreamingRecognizeRequest* msg) {
  return *msg->_impl_.id_;
}
void StreamingRecognizeRequest::set_allocated_streaming_config(::nvidia::riva::asr::StreamingRecognitionConfig* streaming_config) {
  ::google::protobuf::Arena* message_arena = GetArena();
  clear_streaming_request();
  if (streaming_config) {
    ::google::protobuf::Arena* submessage_arena = streaming_config->GetArena();
    if (message_arena != submessage_arena) {
      streaming_config = ::google::protobuf::internal::GetOwnedMessage(message_arena, streaming_config, submessage_arena);
    }
    set_has_streaming_config();
    _impl_.streaming_request_.streaming_config_ = streaming_config;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.riva.asr.StreamingRecognizeRequest.streaming_config)
}
void StreamingRecognizeRequest::clear_id() {
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  if (_impl_.id_ != nullptr) _impl_.id_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
StreamingRecognizeRequest::StreamingRecognizeRequest(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.StreamingRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        streaming_request_{},
        _oneof_case_{from._oneof_case_[0]} {}

StreamingRecognizeRequest::StreamingRecognizeRequest(
    ::google::protobuf::Arena* arena,
    const StreamingRecognizeRequest& from)
    : ::google::protobuf::Message(arena) {
  StreamingRecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.id_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::RequestId>(arena, *from._impl_.id_)
                : nullptr;
  switch (streaming_request_case()) {
    case STREAMING_REQUEST_NOT_SET:
      break;
      case kStreamingConfig:
        _impl_.streaming_request_.streaming_config_ = CreateMaybeMessage<::nvidia::riva::asr::StreamingRecognitionConfig>(arena, *from._impl_.streaming_request_.streaming_config_);
        break;
      case kAudioContent:
        new (&_impl_.streaming_request_.audio_content_) decltype(_impl_.streaming_request_.audio_content_){arena, from._impl_.streaming_request_.audio_content_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.StreamingRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        streaming_request_{},
        _oneof_case_{} {}

inline void StreamingRecognizeRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.id_ = {};
}
StreamingRecognizeRequest::~StreamingRecognizeRequest() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.StreamingRecognizeRequest)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void StreamingRecognizeRequest::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  delete _impl_.id_;
  if (has_streaming_request()) {
    clear_streaming_request();
  }
  _impl_.~Impl_();
}

void StreamingRecognizeRequest::clear_streaming_request() {
// @@protoc_insertion_point(one_of_clear_start:nvidia.riva.asr.StreamingRecognizeRequest)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  switch (streaming_request_case()) {
    case kStreamingConfig: {
      if (GetArena() == nullptr) {
        delete _impl_.streaming_request_.streaming_config_;
      }
      break;
    }
    case kAudioContent: {
      _impl_.streaming_request_.audio_content_.Destroy();
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}


PROTOBUF_NOINLINE void StreamingRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.StreamingRecognizeRequest)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.id_ != nullptr);
    _impl_.id_->Clear();
  }
  clear_streaming_request();
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* StreamingRecognizeRequest::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 3, 2, 0, 7> StreamingRecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    100, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_StreamingRecognizeRequest_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // .nvidia.riva.RequestId id = 100;
    {::_pbi::TcParser::FastMtS2,
     {1698, 0, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.id_)}},
  }}, {{
    100, 0, 1,
    65534, 2,
    65535, 65535
  }}, {{
    // .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.streaming_config_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kMessage | ::_fl::kTvTable)},
    // bytes audio_content = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.audio_content_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kBytes | ::_fl::kRepAString)},
    // .nvidia.riva.RequestId id = 100;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.id_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::StreamingRecognitionConfig>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::RequestId>()},
  }}, {{
  }},
};

::uint8_t* StreamingRecognizeRequest::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.StreamingRecognizeRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  switch (streaming_request_case()) {
    case kStreamingConfig: {
      target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
          1, _Internal::streaming_config(this),
          _Internal::streaming_config(this).GetCachedSize(), target, stream);
      break;
    }
    case kAudioContent: {
      const std::string& _s = this->_internal_audio_content();
      target = stream->WriteBytesMaybeAliased(2, _s, target);
      break;
    }
    default:
      break;
  }
  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.RequestId id = 100;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        100, _Internal::id(this),
        _Internal::id(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.StreamingRecognizeRequest)
  return target;
}

::size_t StreamingRecognizeRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.StreamingRecognizeRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .nvidia.riva.RequestId id = 100;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size +=
        2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.id_);
  }

  switch (streaming_request_case()) {
    // .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;
    case kStreamingConfig: {
      total_size +=
          1 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.streaming_request_.streaming_config_);
      break;
    }
    // bytes audio_content = 2;
    case kAudioContent: {
      total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                      this->_internal_audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData StreamingRecognizeRequest::_class_data_ = {
    StreamingRecognizeRequest::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* StreamingRecognizeRequest::GetClassData() const {
  return &_class_data_;
}

void StreamingRecognizeRequest::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeRequest*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeRequest&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.StreamingRecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if ((from._impl_._has_bits_[0] & 0x00000001u) != 0) {
    _this->_internal_mutable_id()->::nvidia::riva::RequestId::MergeFrom(
        from._internal_id());
  }
  switch (from.streaming_request_case()) {
    case kStreamingConfig: {
      _this->_internal_mutable_streaming_config()->::nvidia::riva::asr::StreamingRecognitionConfig::MergeFrom(
          from._internal_streaming_config());
      break;
    }
    case kAudioContent: {
      _this->_internal_set_audio_content(from._internal_audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeRequest::CopyFrom(const StreamingRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.StreamingRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool StreamingRecognizeRequest::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* StreamingRecognizeRequest::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void StreamingRecognizeRequest::InternalSwap(StreamingRecognizeRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  swap(_impl_.id_, other->_impl_.id_);
  swap(_impl_.streaming_request_, other->_impl_.streaming_request_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata StreamingRecognizeRequest::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[5]);
}
// ===================================================================

class EndpointingConfig::_Internal {
 public:
  using HasBits = decltype(std::declval<EndpointingConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_._has_bits_);
  static void set_has_start_history(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_start_threshold(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_stop_history(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
  static void set_has_stop_threshold(HasBits* has_bits) {
    (*has_bits)[0] |= 8u;
  }
  static void set_has_stop_history_eou(HasBits* has_bits) {
    (*has_bits)[0] |= 16u;
  }
  static void set_has_stop_threshold_eou(HasBits* has_bits) {
    (*has_bits)[0] |= 32u;
  }
};

EndpointingConfig::EndpointingConfig(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.EndpointingConfig)
}
EndpointingConfig::EndpointingConfig(
    ::google::protobuf::Arena* arena, const EndpointingConfig& from)
    : EndpointingConfig(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE EndpointingConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void EndpointingConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_history_),
           0,
           offsetof(Impl_, stop_threshold_eou_) -
               offsetof(Impl_, start_history_) +
               sizeof(Impl_::stop_threshold_eou_));
}
EndpointingConfig::~EndpointingConfig() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.EndpointingConfig)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void EndpointingConfig::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void EndpointingConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.EndpointingConfig)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    ::memset(&_impl_.start_history_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.stop_threshold_eou_) -
        reinterpret_cast<char*>(&_impl_.start_history_)) + sizeof(_impl_.stop_threshold_eou_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* EndpointingConfig::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 0, 0, 2> EndpointingConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_EndpointingConfig_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // optional int32 start_history = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(EndpointingConfig, _impl_.start_history_), 0>(),
     {8, 0, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.start_history_)}},
    // optional float start_threshold = 2;
    {::_pbi::TcParser::FastF32S1,
     {21, 1, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.start_threshold_)}},
    // optional int32 stop_history = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(EndpointingConfig, _impl_.stop_history_), 2>(),
     {24, 2, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_history_)}},
    // optional float stop_threshold = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 3, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_threshold_)}},
    // optional int32 stop_history_eou = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(EndpointingConfig, _impl_.stop_history_eou_), 4>(),
     {40, 4, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_history_eou_)}},
    // optional float stop_threshold_eou = 6;
    {::_pbi::TcParser::FastF32S1,
     {53, 5, 0, PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_threshold_eou_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // optional int32 start_history = 1;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.start_history_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // optional float start_threshold = 2;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.start_threshold_), _Internal::kHasBitsOffset + 1, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
    // optional int32 stop_history = 3;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_history_), _Internal::kHasBitsOffset + 2, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // optional float stop_threshold = 4;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_threshold_), _Internal::kHasBitsOffset + 3, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
    // optional int32 stop_history_eou = 5;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_history_eou_), _Internal::kHasBitsOffset + 4, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // optional float stop_threshold_eou = 6;
    {PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_threshold_eou_), _Internal::kHasBitsOffset + 5, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
  }},
  // no aux_entries
  {{
  }},
};

::uint8_t* EndpointingConfig::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.EndpointingConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  // optional int32 start_history = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<1>(
            stream, this->_internal_start_history(), target);
  }

  // optional float start_threshold = 2;
  if (cached_has_bits & 0x00000002u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        2, this->_internal_start_threshold(), target);
  }

  // optional int32 stop_history = 3;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<3>(
            stream, this->_internal_stop_history(), target);
  }

  // optional float stop_threshold = 4;
  if (cached_has_bits & 0x00000008u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        4, this->_internal_stop_threshold(), target);
  }

  // optional int32 stop_history_eou = 5;
  if (cached_has_bits & 0x00000010u) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<5>(
            stream, this->_internal_stop_history_eou(), target);
  }

  // optional float stop_threshold_eou = 6;
  if (cached_has_bits & 0x00000020u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        6, this->_internal_stop_threshold_eou(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.EndpointingConfig)
  return target;
}

::size_t EndpointingConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.EndpointingConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    // optional int32 start_history = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
          this->_internal_start_history());
    }

    // optional float start_threshold = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 5;
    }

    // optional int32 stop_history = 3;
    if (cached_has_bits & 0x00000004u) {
      total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
          this->_internal_stop_history());
    }

    // optional float stop_threshold = 4;
    if (cached_has_bits & 0x00000008u) {
      total_size += 5;
    }

    // optional int32 stop_history_eou = 5;
    if (cached_has_bits & 0x00000010u) {
      total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
          this->_internal_stop_history_eou());
    }

    // optional float stop_threshold_eou = 6;
    if (cached_has_bits & 0x00000020u) {
      total_size += 5;
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData EndpointingConfig::_class_data_ = {
    EndpointingConfig::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* EndpointingConfig::GetClassData() const {
  return &_class_data_;
}

void EndpointingConfig::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<EndpointingConfig*>(&to_msg);
  auto& from = static_cast<const EndpointingConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.EndpointingConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    if (cached_has_bits & 0x00000001u) {
      _this->_impl_.start_history_ = from._impl_.start_history_;
    }
    if (cached_has_bits & 0x00000002u) {
      _this->_impl_.start_threshold_ = from._impl_.start_threshold_;
    }
    if (cached_has_bits & 0x00000004u) {
      _this->_impl_.stop_history_ = from._impl_.stop_history_;
    }
    if (cached_has_bits & 0x00000008u) {
      _this->_impl_.stop_threshold_ = from._impl_.stop_threshold_;
    }
    if (cached_has_bits & 0x00000010u) {
      _this->_impl_.stop_history_eou_ = from._impl_.stop_history_eou_;
    }
    if (cached_has_bits & 0x00000020u) {
      _this->_impl_.stop_threshold_eou_ = from._impl_.stop_threshold_eou_;
    }
    _this->_impl_._has_bits_[0] |= cached_has_bits;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void EndpointingConfig::CopyFrom(const EndpointingConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.EndpointingConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool EndpointingConfig::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* EndpointingConfig::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void EndpointingConfig::InternalSwap(EndpointingConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.stop_threshold_eou_)
      + sizeof(EndpointingConfig::_impl_.stop_threshold_eou_)
      - PROTOBUF_FIELD_OFFSET(EndpointingConfig, _impl_.start_history_)>(
          reinterpret_cast<char*>(&_impl_.start_history_),
          reinterpret_cast<char*>(&other->_impl_.start_history_));
}

::google::protobuf::Metadata EndpointingConfig::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[6]);
}
// ===================================================================

RecognitionConfig_CustomConfigurationEntry_DoNotUse::RecognitionConfig_CustomConfigurationEntry_DoNotUse() {}
RecognitionConfig_CustomConfigurationEntry_DoNotUse::RecognitionConfig_CustomConfigurationEntry_DoNotUse(::google::protobuf::Arena* arena)
    : SuperType(arena) {}
::google::protobuf::Metadata RecognitionConfig_CustomConfigurationEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[7]);
}
// ===================================================================

class RecognitionConfig::_Internal {
 public:
  using HasBits = decltype(std::declval<RecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_);
  static const ::nvidia::riva::asr::SpeakerDiarizationConfig& diarization_config(const RecognitionConfig* msg);
  static void set_has_diarization_config(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static const ::nvidia::riva::asr::EndpointingConfig& endpointing_config(const RecognitionConfig* msg);
  static void set_has_endpointing_config(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

const ::nvidia::riva::asr::SpeakerDiarizationConfig& RecognitionConfig::_Internal::diarization_config(const RecognitionConfig* msg) {
  return *msg->_impl_.diarization_config_;
}
const ::nvidia::riva::asr::EndpointingConfig& RecognitionConfig::_Internal::endpointing_config(const RecognitionConfig* msg) {
  return *msg->_impl_.endpointing_config_;
}
RecognitionConfig::RecognitionConfig(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        speech_contexts_{visibility, arena, from.speech_contexts_},
        custom_configuration_{visibility, arena, from.custom_configuration_},
        language_code_(arena, from.language_code_),
        model_(arena, from.model_) {}

RecognitionConfig::RecognitionConfig(
    ::google::protobuf::Arena* arena,
    const RecognitionConfig& from)
    : ::google::protobuf::Message(arena) {
  RecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.diarization_config_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::asr::SpeakerDiarizationConfig>(arena, *from._impl_.diarization_config_)
                : nullptr;
  _impl_.endpointing_config_ = (cached_has_bits & 0x00000002u)
                ? CreateMaybeMessage<::nvidia::riva::asr::EndpointingConfig>(arena, *from._impl_.endpointing_config_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, encoding_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, encoding_),
           offsetof(Impl_, verbatim_transcripts_) -
               offsetof(Impl_, encoding_) +
               sizeof(Impl_::verbatim_transcripts_));

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        speech_contexts_{visibility, arena},
        custom_configuration_{visibility, arena},
        language_code_(arena),
        model_(arena) {}

inline void RecognitionConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, diarization_config_),
           0,
           offsetof(Impl_, verbatim_transcripts_) -
               offsetof(Impl_, diarization_config_) +
               sizeof(Impl_::verbatim_transcripts_));
}
RecognitionConfig::~RecognitionConfig() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RecognitionConfig)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RecognitionConfig::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.language_code_.Destroy();
  _impl_.model_.Destroy();
  delete _impl_.diarization_config_;
  delete _impl_.endpointing_config_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RecognitionConfig)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.speech_contexts_.Clear();
  _impl_.custom_configuration_.Clear();
  _impl_.language_code_.ClearToEmpty();
  _impl_.model_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.diarization_config_ != nullptr);
      _impl_.diarization_config_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.endpointing_config_ != nullptr);
      _impl_.endpointing_config_->Clear();
    }
  }
  ::memset(&_impl_.encoding_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.verbatim_transcripts_) -
      reinterpret_cast<char*>(&_impl_.encoding_)) + sizeof(_impl_.verbatim_transcripts_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RecognitionConfig::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<4, 15, 4, 88, 2> RecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    25, 120,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4269523712,  // skipmap
    offsetof(decltype(_table_), field_entries),
    15,  // num_field_entries
    4,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_RecognitionConfig_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .nvidia.riva.AudioEncoding encoding = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.encoding_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_)}},
    // int32 sample_rate_hertz = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.sample_rate_hertz_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_)}},
    // string language_code = 3;
    {::_pbi::TcParser::FastUS1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_)}},
    // int32 max_alternatives = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.max_alternatives_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_)}},
    // bool profanity_filter = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.profanity_filter_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_)}},
    // repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;
    {::_pbi::TcParser::FastMtR1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_)}},
    // int32 audio_channel_count = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.audio_channel_count_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_)}},
    // bool enable_word_time_offsets = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_word_time_offsets_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_)}},
    // optional .nvidia.riva.asr.EndpointingConfig endpointing_config = 25;
    {::_pbi::TcParser::FastMtS2,
     {458, 1, 3, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.endpointing_config_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_automatic_punctuation = 11;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_automatic_punctuation_), 63>(),
     {88, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_)}},
    // bool enable_separate_recognition_per_channel = 12;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), 63>(),
     {96, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_)}},
    // string model = 13;
    {::_pbi::TcParser::FastUS1,
     {106, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_)}},
    // bool verbatim_transcripts = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.verbatim_transcripts_), 63>(),
     {112, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.verbatim_transcripts_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .nvidia.riva.AudioEncoding encoding = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // int32 sample_rate_hertz = 2;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string language_code = 3;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 max_alternatives = 4;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool profanity_filter = 5;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 audio_channel_count = 7;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool enable_word_time_offsets = 8;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_automatic_punctuation = 11;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_separate_recognition_per_channel = 12;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // string model = 13;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // bool verbatim_transcripts = 14;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.verbatim_transcripts_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .nvidia.riva.asr.SpeakerDiarizationConfig diarization_config = 19;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // map<string, string> custom_configuration = 24;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.custom_configuration_), -1, 2,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
    // optional .nvidia.riva.asr.EndpointingConfig endpointing_config = 25;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.endpointing_config_), _Internal::kHasBitsOffset + 1, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::SpeechContext>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::SpeakerDiarizationConfig>()},
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(RecognitionConfig()._impl_.custom_configuration_)>(
        1, 0, 0, 9,
        9)},
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::EndpointingConfig>()},
  }}, {{
    "\41\0\0\15\0\0\0\0\0\0\0\5\0\0\24\0"
    "nvidia.riva.asr.RecognitionConfig"
    "language_code"
    "model"
    "custom_configuration"
  }},
};

::uint8_t* RecognitionConfig::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RecognitionConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // .nvidia.riva.AudioEncoding encoding = 1;
  if (this->_internal_encoding() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
        1, this->_internal_encoding(), target);
  }

  // int32 sample_rate_hertz = 2;
  if (this->_internal_sample_rate_hertz() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<2>(
            stream, this->_internal_sample_rate_hertz(), target);
  }

  // string language_code = 3;
  if (!this->_internal_language_code().empty()) {
    const std::string& _s = this->_internal_language_code();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.language_code");
    target = stream->WriteStringMaybeAliased(3, _s, target);
  }

  // int32 max_alternatives = 4;
  if (this->_internal_max_alternatives() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<4>(
            stream, this->_internal_max_alternatives(), target);
  }

  // bool profanity_filter = 5;
  if (this->_internal_profanity_filter() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        5, this->_internal_profanity_filter(), target);
  }

  // repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_speech_contexts_size()); i < n; i++) {
    const auto& repfield = this->_internal_speech_contexts().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(6, repfield, repfield.GetCachedSize(), target, stream);
  }

  // int32 audio_channel_count = 7;
  if (this->_internal_audio_channel_count() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<7>(
            stream, this->_internal_audio_channel_count(), target);
  }

  // bool enable_word_time_offsets = 8;
  if (this->_internal_enable_word_time_offsets() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        8, this->_internal_enable_word_time_offsets(), target);
  }

  // bool enable_automatic_punctuation = 11;
  if (this->_internal_enable_automatic_punctuation() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        11, this->_internal_enable_automatic_punctuation(), target);
  }

  // bool enable_separate_recognition_per_channel = 12;
  if (this->_internal_enable_separate_recognition_per_channel() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        12, this->_internal_enable_separate_recognition_per_channel(), target);
  }

  // string model = 13;
  if (!this->_internal_model().empty()) {
    const std::string& _s = this->_internal_model();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.model");
    target = stream->WriteStringMaybeAliased(13, _s, target);
  }

  // bool verbatim_transcripts = 14;
  if (this->_internal_verbatim_transcripts() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        14, this->_internal_verbatim_transcripts(), target);
  }

  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.asr.SpeakerDiarizationConfig diarization_config = 19;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        19, _Internal::diarization_config(this),
        _Internal::diarization_config(this).GetCachedSize(), target, stream);
  }

  // map<string, string> custom_configuration = 24;
  if (!_internal_custom_configuration().empty()) {
    using MapType = ::google::protobuf::Map<std::string, std::string>;
    using WireHelper = _pbi::MapEntryFuncs<std::string, std::string,
                                   _pbi::WireFormatLite::TYPE_STRING,
                                   _pbi::WireFormatLite::TYPE_STRING>;
    const auto& field = _internal_custom_configuration();

    if (stream->IsSerializationDeterministic() && field.size() > 1) {
      for (const auto& entry : ::google::protobuf::internal::MapSorterPtr<MapType>(field)) {
        target = WireHelper::InternalSerialize(
            24, entry.first, entry.second, target, stream);
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.custom_configuration");
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.custom_configuration");
      }
    } else {
      for (const auto& entry : field) {
        target = WireHelper::InternalSerialize(
            24, entry.first, entry.second, target, stream);
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.custom_configuration");
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.RecognitionConfig.custom_configuration");
      }
    }
  }

  // optional .nvidia.riva.asr.EndpointingConfig endpointing_config = 25;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        25, _Internal::endpointing_config(this),
        _Internal::endpointing_config(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RecognitionConfig)
  return target;
}

::size_t RecognitionConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RecognitionConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;
  total_size += 1UL * this->_internal_speech_contexts_size();
  for (const auto& msg : this->_internal_speech_contexts()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // map<string, string> custom_configuration = 24;
  total_size += 2 * ::google::protobuf::internal::FromIntSize(_internal_custom_configuration_size());
  for (const auto& entry : _internal_custom_configuration()) {
    total_size += _pbi::MapEntryFuncs<std::string, std::string,
                                   _pbi::WireFormatLite::TYPE_STRING,
                                   _pbi::WireFormatLite::TYPE_STRING>::ByteSizeLong(entry.first, entry.second);
  }
  // string language_code = 3;
  if (!this->_internal_language_code().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_language_code());
  }

  // string model = 13;
  if (!this->_internal_model().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_model());
  }

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    // .nvidia.riva.asr.SpeakerDiarizationConfig diarization_config = 19;
    if (cached_has_bits & 0x00000001u) {
      total_size +=
          2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.diarization_config_);
    }

    // optional .nvidia.riva.asr.EndpointingConfig endpointing_config = 25;
    if (cached_has_bits & 0x00000002u) {
      total_size +=
          2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.endpointing_config_);
    }

  }
  // .nvidia.riva.AudioEncoding encoding = 1;
  if (this->_internal_encoding() != 0) {
    total_size += 1 +
                  ::_pbi::WireFormatLite::EnumSize(this->_internal_encoding());
  }

  // int32 sample_rate_hertz = 2;
  if (this->_internal_sample_rate_hertz() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_sample_rate_hertz());
  }

  // int32 max_alternatives = 4;
  if (this->_internal_max_alternatives() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_max_alternatives());
  }

  // int32 audio_channel_count = 7;
  if (this->_internal_audio_channel_count() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_audio_channel_count());
  }

  // bool profanity_filter = 5;
  if (this->_internal_profanity_filter() != 0) {
    total_size += 2;
  }

  // bool enable_word_time_offsets = 8;
  if (this->_internal_enable_word_time_offsets() != 0) {
    total_size += 2;
  }

  // bool enable_automatic_punctuation = 11;
  if (this->_internal_enable_automatic_punctuation() != 0) {
    total_size += 2;
  }

  // bool enable_separate_recognition_per_channel = 12;
  if (this->_internal_enable_separate_recognition_per_channel() != 0) {
    total_size += 2;
  }

  // bool verbatim_transcripts = 14;
  if (this->_internal_verbatim_transcripts() != 0) {
    total_size += 2;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RecognitionConfig::_class_data_ = {
    RecognitionConfig::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RecognitionConfig::GetClassData() const {
  return &_class_data_;
}

void RecognitionConfig::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RecognitionConfig*>(&to_msg);
  auto& from = static_cast<const RecognitionConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_speech_contexts()->MergeFrom(
      from._internal_speech_contexts());
  _this->_impl_.custom_configuration_.MergeFrom(from._impl_.custom_configuration_);
  if (!from._internal_language_code().empty()) {
    _this->_internal_set_language_code(from._internal_language_code());
  }
  if (!from._internal_model().empty()) {
    _this->_internal_set_model(from._internal_model());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      _this->_internal_mutable_diarization_config()->::nvidia::riva::asr::SpeakerDiarizationConfig::MergeFrom(
          from._internal_diarization_config());
    }
    if (cached_has_bits & 0x00000002u) {
      _this->_internal_mutable_endpointing_config()->::nvidia::riva::asr::EndpointingConfig::MergeFrom(
          from._internal_endpointing_config());
    }
  }
  if (from._internal_encoding() != 0) {
    _this->_internal_set_encoding(from._internal_encoding());
  }
  if (from._internal_sample_rate_hertz() != 0) {
    _this->_internal_set_sample_rate_hertz(from._internal_sample_rate_hertz());
  }
  if (from._internal_max_alternatives() != 0) {
    _this->_internal_set_max_alternatives(from._internal_max_alternatives());
  }
  if (from._internal_audio_channel_count() != 0) {
    _this->_internal_set_audio_channel_count(from._internal_audio_channel_count());
  }
  if (from._internal_profanity_filter() != 0) {
    _this->_internal_set_profanity_filter(from._internal_profanity_filter());
  }
  if (from._internal_enable_word_time_offsets() != 0) {
    _this->_internal_set_enable_word_time_offsets(from._internal_enable_word_time_offsets());
  }
  if (from._internal_enable_automatic_punctuation() != 0) {
    _this->_internal_set_enable_automatic_punctuation(from._internal_enable_automatic_punctuation());
  }
  if (from._internal_enable_separate_recognition_per_channel() != 0) {
    _this->_internal_set_enable_separate_recognition_per_channel(from._internal_enable_separate_recognition_per_channel());
  }
  if (from._internal_verbatim_transcripts() != 0) {
    _this->_internal_set_verbatim_transcripts(from._internal_verbatim_transcripts());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionConfig::CopyFrom(const RecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RecognitionConfig::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RecognitionConfig::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RecognitionConfig::InternalSwap(RecognitionConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.speech_contexts_.InternalSwap(&other->_impl_.speech_contexts_);
  _impl_.custom_configuration_.InternalSwap(&other->_impl_.custom_configuration_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.model_, &other->_impl_.model_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.verbatim_transcripts_)
      + sizeof(RecognitionConfig::_impl_.verbatim_transcripts_)
      - PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_)>(
          reinterpret_cast<char*>(&_impl_.diarization_config_),
          reinterpret_cast<char*>(&other->_impl_.diarization_config_));
}

::google::protobuf::Metadata RecognitionConfig::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[8]);
}
// ===================================================================

class StreamingRecognitionConfig::_Internal {
 public:
  using HasBits = decltype(std::declval<StreamingRecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_);
  static const ::nvidia::riva::asr::RecognitionConfig& config(const StreamingRecognitionConfig* msg);
  static void set_has_config(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

const ::nvidia::riva::asr::RecognitionConfig& StreamingRecognitionConfig::_Internal::config(const StreamingRecognitionConfig* msg) {
  return *msg->_impl_.config_;
}
StreamingRecognitionConfig::StreamingRecognitionConfig(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.StreamingRecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

StreamingRecognitionConfig::StreamingRecognitionConfig(
    ::google::protobuf::Arena* arena,
    const StreamingRecognitionConfig& from)
    : ::google::protobuf::Message(arena) {
  StreamingRecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::asr::RecognitionConfig>(arena, *from._impl_.config_)
                : nullptr;
  _impl_.interim_results_ = from._impl_.interim_results_;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.StreamingRecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void StreamingRecognitionConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, interim_results_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::interim_results_));
}
StreamingRecognitionConfig::~StreamingRecognitionConfig() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.StreamingRecognitionConfig)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void StreamingRecognitionConfig::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  delete _impl_.config_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void StreamingRecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.StreamingRecognitionConfig)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.config_ != nullptr);
    _impl_.config_->Clear();
  }
  _impl_.interim_results_ = false;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* StreamingRecognitionConfig::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 1, 0, 2> StreamingRecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_StreamingRecognitionConfig_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // bool interim_results = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.interim_results_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_)}},
    // .nvidia.riva.asr.RecognitionConfig config = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .nvidia.riva.asr.RecognitionConfig config = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool interim_results = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::RecognitionConfig>()},
  }}, {{
  }},
};

::uint8_t* StreamingRecognitionConfig::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.StreamingRecognitionConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.asr.RecognitionConfig config = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, _Internal::config(this),
        _Internal::config(this).GetCachedSize(), target, stream);
  }

  // bool interim_results = 2;
  if (this->_internal_interim_results() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        2, this->_internal_interim_results(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.StreamingRecognitionConfig)
  return target;
}

::size_t StreamingRecognitionConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.StreamingRecognitionConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .nvidia.riva.asr.RecognitionConfig config = 1;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size +=
        1 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.config_);
  }

  // bool interim_results = 2;
  if (this->_internal_interim_results() != 0) {
    total_size += 2;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData StreamingRecognitionConfig::_class_data_ = {
    StreamingRecognitionConfig::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* StreamingRecognitionConfig::GetClassData() const {
  return &_class_data_;
}

void StreamingRecognitionConfig::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionConfig*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.StreamingRecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if ((from._impl_._has_bits_[0] & 0x00000001u) != 0) {
    _this->_internal_mutable_config()->::nvidia::riva::asr::RecognitionConfig::MergeFrom(
        from._internal_config());
  }
  if (from._internal_interim_results() != 0) {
    _this->_internal_set_interim_results(from._internal_interim_results());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionConfig::CopyFrom(const StreamingRecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.StreamingRecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool StreamingRecognitionConfig::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* StreamingRecognitionConfig::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void StreamingRecognitionConfig::InternalSwap(StreamingRecognitionConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_)
      + sizeof(StreamingRecognitionConfig::_impl_.interim_results_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata StreamingRecognitionConfig::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[9]);
}
// ===================================================================

class SpeakerDiarizationConfig::_Internal {
 public:
};

SpeakerDiarizationConfig::SpeakerDiarizationConfig(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.SpeakerDiarizationConfig)
}
SpeakerDiarizationConfig::SpeakerDiarizationConfig(
    ::google::protobuf::Arena* arena, const SpeakerDiarizationConfig& from)
    : SpeakerDiarizationConfig(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE SpeakerDiarizationConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void SpeakerDiarizationConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, enable_speaker_diarization_),
           0,
           offsetof(Impl_, max_speaker_count_) -
               offsetof(Impl_, enable_speaker_diarization_) +
               sizeof(Impl_::max_speaker_count_));
}
SpeakerDiarizationConfig::~SpeakerDiarizationConfig() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.SpeakerDiarizationConfig)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void SpeakerDiarizationConfig::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void SpeakerDiarizationConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.SpeakerDiarizationConfig)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.enable_speaker_diarization_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.max_speaker_count_) -
      reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_)) + sizeof(_impl_.max_speaker_count_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* SpeakerDiarizationConfig::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 0, 2> SpeakerDiarizationConfig::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_SpeakerDiarizationConfig_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // int32 max_speaker_count = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.max_speaker_count_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_)}},
    // bool enable_speaker_diarization = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)}},
  }}, {{
    65535, 65535
  }}, {{
    // bool enable_speaker_diarization = 1;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 max_speaker_count = 2;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
  }},
  // no aux_entries
  {{
  }},
};

::uint8_t* SpeakerDiarizationConfig::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.SpeakerDiarizationConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // bool enable_speaker_diarization = 1;
  if (this->_internal_enable_speaker_diarization() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        1, this->_internal_enable_speaker_diarization(), target);
  }

  // int32 max_speaker_count = 2;
  if (this->_internal_max_speaker_count() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<2>(
            stream, this->_internal_max_speaker_count(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.SpeakerDiarizationConfig)
  return target;
}

::size_t SpeakerDiarizationConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.SpeakerDiarizationConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // bool enable_speaker_diarization = 1;
  if (this->_internal_enable_speaker_diarization() != 0) {
    total_size += 2;
  }

  // int32 max_speaker_count = 2;
  if (this->_internal_max_speaker_count() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_max_speaker_count());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData SpeakerDiarizationConfig::_class_data_ = {
    SpeakerDiarizationConfig::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* SpeakerDiarizationConfig::GetClassData() const {
  return &_class_data_;
}

void SpeakerDiarizationConfig::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<SpeakerDiarizationConfig*>(&to_msg);
  auto& from = static_cast<const SpeakerDiarizationConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.SpeakerDiarizationConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_enable_speaker_diarization() != 0) {
    _this->_internal_set_enable_speaker_diarization(from._internal_enable_speaker_diarization());
  }
  if (from._internal_max_speaker_count() != 0) {
    _this->_internal_set_max_speaker_count(from._internal_max_speaker_count());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeakerDiarizationConfig::CopyFrom(const SpeakerDiarizationConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.SpeakerDiarizationConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool SpeakerDiarizationConfig::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* SpeakerDiarizationConfig::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void SpeakerDiarizationConfig::InternalSwap(SpeakerDiarizationConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_)
      + sizeof(SpeakerDiarizationConfig::_impl_.max_speaker_count_)
      - PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)>(
          reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_),
          reinterpret_cast<char*>(&other->_impl_.enable_speaker_diarization_));
}

::google::protobuf::Metadata SpeakerDiarizationConfig::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[10]);
}
// ===================================================================

class SpeechContext::_Internal {
 public:
};

SpeechContext::SpeechContext(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.SpeechContext)
}
inline PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : phrases_{visibility, arena, from.phrases_},
        _cached_size_{0} {}

SpeechContext::SpeechContext(
    ::google::protobuf::Arena* arena,
    const SpeechContext& from)
    : ::google::protobuf::Message(arena) {
  SpeechContext* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  _impl_.boost_ = from._impl_.boost_;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.SpeechContext)
}
inline PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : phrases_{visibility, arena},
        _cached_size_{0} {}

inline void SpeechContext::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.boost_ = {};
}
SpeechContext::~SpeechContext() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.SpeechContext)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void SpeechContext::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void SpeechContext::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.SpeechContext)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.phrases_.Clear();
  _impl_.boost_ = 0;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* SpeechContext::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 45, 2> SpeechContext::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    4, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967286,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_SpeechContext_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // float boost = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_)}},
    // repeated string phrases = 1;
    {::_pbi::TcParser::FastUR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated string phrases = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // float boost = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
  }},
  // no aux_entries
  {{
    "\35\7\0\0\0\0\0\0"
    "nvidia.riva.asr.SpeechContext"
    "phrases"
  }},
};

::uint8_t* SpeechContext::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.SpeechContext)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated string phrases = 1;
  for (int i = 0, n = this->_internal_phrases_size(); i < n; ++i) {
    const auto& s = this->_internal_phrases().Get(i);
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.SpeechContext.phrases");
    target = stream->WriteString(1, s, target);
  }

  // float boost = 4;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_boost = this->_internal_boost();
  ::uint32_t raw_boost;
  memcpy(&raw_boost, &tmp_boost, sizeof(tmp_boost));
  if (raw_boost != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        4, this->_internal_boost(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.SpeechContext)
  return target;
}

::size_t SpeechContext::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.SpeechContext)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated string phrases = 1;
  total_size += 1 * ::google::protobuf::internal::FromIntSize(_internal_phrases().size());
  for (int i = 0, n = _internal_phrases().size(); i < n; ++i) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
        _internal_phrases().Get(i));
  }
  // float boost = 4;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_boost = this->_internal_boost();
  ::uint32_t raw_boost;
  memcpy(&raw_boost, &tmp_boost, sizeof(tmp_boost));
  if (raw_boost != 0) {
    total_size += 5;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData SpeechContext::_class_data_ = {
    SpeechContext::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* SpeechContext::GetClassData() const {
  return &_class_data_;
}

void SpeechContext::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<SpeechContext*>(&to_msg);
  auto& from = static_cast<const SpeechContext&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.SpeechContext)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_phrases()->MergeFrom(from._internal_phrases());
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_boost = from._internal_boost();
  ::uint32_t raw_boost;
  memcpy(&raw_boost, &tmp_boost, sizeof(tmp_boost));
  if (raw_boost != 0) {
    _this->_internal_set_boost(from._internal_boost());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechContext::CopyFrom(const SpeechContext& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.SpeechContext)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool SpeechContext::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* SpeechContext::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void SpeechContext::InternalSwap(SpeechContext* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.phrases_.InternalSwap(&other->_impl_.phrases_);
        swap(_impl_.boost_, other->_impl_.boost_);
}

::google::protobuf::Metadata SpeechContext::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[11]);
}
// ===================================================================

class RecognizeResponse::_Internal {
 public:
  using HasBits = decltype(std::declval<RecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_);
  static const ::nvidia::riva::RequestId& id(const RecognizeResponse* msg);
  static void set_has_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

const ::nvidia::riva::RequestId& RecognizeResponse::_Internal::id(const RecognizeResponse* msg) {
  return *msg->_impl_.id_;
}
void RecognizeResponse::clear_id() {
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  if (_impl_.id_ != nullptr) _impl_.id_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
RecognizeResponse::RecognizeResponse(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.RecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

RecognizeResponse::RecognizeResponse(
    ::google::protobuf::Arena* arena,
    const RecognizeResponse& from)
    : ::google::protobuf::Message(arena) {
  RecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.id_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::RequestId>(arena, *from._impl_.id_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.RecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void RecognizeResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.id_ = {};
}
RecognizeResponse::~RecognizeResponse() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.RecognizeResponse)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void RecognizeResponse::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  delete _impl_.id_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void RecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.RecognizeResponse)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.id_ != nullptr);
    _impl_.id_->Clear();
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* RecognizeResponse::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 7> RecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    100, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_RecognizeResponse_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // .nvidia.riva.RequestId id = 100;
    {::_pbi::TcParser::FastMtS2,
     {1698, 0, 1, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.id_)}},
    // repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_)}},
  }}, {{
    100, 0, 1,
    65534, 1,
    65535, 65535
  }}, {{
    // repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .nvidia.riva.RequestId id = 100;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.id_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::SpeechRecognitionResult>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::RequestId>()},
  }}, {{
  }},
};

::uint8_t* RecognizeResponse::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.RecognizeResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_results_size()); i < n; i++) {
    const auto& repfield = this->_internal_results().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.RequestId id = 100;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        100, _Internal::id(this),
        _Internal::id(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.RecognizeResponse)
  return target;
}

::size_t RecognizeResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.RecognizeResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;
  total_size += 1UL * this->_internal_results_size();
  for (const auto& msg : this->_internal_results()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // .nvidia.riva.RequestId id = 100;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size +=
        2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.id_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData RecognizeResponse::_class_data_ = {
    RecognizeResponse::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* RecognizeResponse::GetClassData() const {
  return &_class_data_;
}

void RecognizeResponse::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<RecognizeResponse*>(&to_msg);
  auto& from = static_cast<const RecognizeResponse&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.RecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  if ((from._impl_._has_bits_[0] & 0x00000001u) != 0) {
    _this->_internal_mutable_id()->::nvidia::riva::RequestId::MergeFrom(
        from._internal_id());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeResponse::CopyFrom(const RecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.RecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool RecognizeResponse::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* RecognizeResponse::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void RecognizeResponse::InternalSwap(RecognizeResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  swap(_impl_.id_, other->_impl_.id_);
}

::google::protobuf::Metadata RecognizeResponse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[12]);
}
// ===================================================================

class SpeechRecognitionResult::_Internal {
 public:
};

SpeechRecognitionResult::SpeechRecognitionResult(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.SpeechRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : alternatives_{visibility, arena, from.alternatives_},
        _cached_size_{0} {}

SpeechRecognitionResult::SpeechRecognitionResult(
    ::google::protobuf::Arena* arena,
    const SpeechRecognitionResult& from)
    : ::google::protobuf::Message(arena) {
  SpeechRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, channel_tag_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, channel_tag_),
           offsetof(Impl_, audio_processed_) -
               offsetof(Impl_, channel_tag_) +
               sizeof(Impl_::audio_processed_));

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.SpeechRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : alternatives_{visibility, arena},
        _cached_size_{0} {}

inline void SpeechRecognitionResult::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, channel_tag_),
           0,
           offsetof(Impl_, audio_processed_) -
               offsetof(Impl_, channel_tag_) +
               sizeof(Impl_::audio_processed_));
}
SpeechRecognitionResult::~SpeechRecognitionResult() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.SpeechRecognitionResult)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void SpeechRecognitionResult::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void SpeechRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.SpeechRecognitionResult)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  ::memset(&_impl_.channel_tag_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.audio_processed_) -
      reinterpret_cast<char*>(&_impl_.channel_tag_)) + sizeof(_impl_.audio_processed_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* SpeechRecognitionResult::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 1, 0, 2> SpeechRecognitionResult::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_SpeechRecognitionResult_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_)}},
    // int32 channel_tag = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeechRecognitionResult, _impl_.channel_tag_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)}},
    // float audio_processed = 3;
    {::_pbi::TcParser::FastF32S1,
     {29, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.audio_processed_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 channel_tag = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // float audio_processed = 3;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.audio_processed_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::SpeechRecognitionAlternative>()},
  }}, {{
  }},
};

::uint8_t* SpeechRecognitionResult::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.SpeechRecognitionResult)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_alternatives_size()); i < n; i++) {
    const auto& repfield = this->_internal_alternatives().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  // int32 channel_tag = 2;
  if (this->_internal_channel_tag() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<2>(
            stream, this->_internal_channel_tag(), target);
  }

  // float audio_processed = 3;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = this->_internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        3, this->_internal_audio_processed(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.SpeechRecognitionResult)
  return target;
}

::size_t SpeechRecognitionResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.SpeechRecognitionResult)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
  total_size += 1UL * this->_internal_alternatives_size();
  for (const auto& msg : this->_internal_alternatives()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // int32 channel_tag = 2;
  if (this->_internal_channel_tag() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_channel_tag());
  }

  // float audio_processed = 3;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = this->_internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    total_size += 5;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData SpeechRecognitionResult::_class_data_ = {
    SpeechRecognitionResult::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* SpeechRecognitionResult::GetClassData() const {
  return &_class_data_;
}

void SpeechRecognitionResult::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionResult*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionResult&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.SpeechRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  if (from._internal_channel_tag() != 0) {
    _this->_internal_set_channel_tag(from._internal_channel_tag());
  }
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = from._internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    _this->_internal_set_audio_processed(from._internal_audio_processed());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionResult::CopyFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool SpeechRecognitionResult::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* SpeechRecognitionResult::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void SpeechRecognitionResult::InternalSwap(SpeechRecognitionResult* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.audio_processed_)
      + sizeof(SpeechRecognitionResult::_impl_.audio_processed_)
      - PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)>(
          reinterpret_cast<char*>(&_impl_.channel_tag_),
          reinterpret_cast<char*>(&other->_impl_.channel_tag_));
}

::google::protobuf::Metadata SpeechRecognitionResult::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[13]);
}
// ===================================================================

class SpeechRecognitionAlternative::_Internal {
 public:
};

SpeechRecognitionAlternative::SpeechRecognitionAlternative(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.SpeechRecognitionAlternative)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : words_{visibility, arena, from.words_},
        language_code_{visibility, arena, from.language_code_},
        transcript_(arena, from.transcript_),
        _cached_size_{0} {}

SpeechRecognitionAlternative::SpeechRecognitionAlternative(
    ::google::protobuf::Arena* arena,
    const SpeechRecognitionAlternative& from)
    : ::google::protobuf::Message(arena) {
  SpeechRecognitionAlternative* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  _impl_.confidence_ = from._impl_.confidence_;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.SpeechRecognitionAlternative)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : words_{visibility, arena},
        language_code_{visibility, arena},
        transcript_(arena),
        _cached_size_{0} {}

inline void SpeechRecognitionAlternative::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.confidence_ = {};
}
SpeechRecognitionAlternative::~SpeechRecognitionAlternative() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.SpeechRecognitionAlternative)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void SpeechRecognitionAlternative::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.transcript_.Destroy();
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void SpeechRecognitionAlternative::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.SpeechRecognitionAlternative)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.words_.Clear();
  _impl_.language_code_.Clear();
  _impl_.transcript_.ClearToEmpty();
  _impl_.confidence_ = 0;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* SpeechRecognitionAlternative::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 4, 1, 76, 2> SpeechRecognitionAlternative::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967280,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_SpeechRecognitionAlternative_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // repeated string language_code = 4;
    {::_pbi::TcParser::FastUR1,
     {34, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.language_code_)}},
    // string transcript = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_)}},
    // float confidence = 2;
    {::_pbi::TcParser::FastF32S1,
     {21, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_)}},
    // repeated .nvidia.riva.asr.WordInfo words = 3;
    {::_pbi::TcParser::FastMtR1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string transcript = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // repeated .nvidia.riva.asr.WordInfo words = 3;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated string language_code = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.language_code_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::WordInfo>()},
  }}, {{
    "\54\12\0\0\15\0\0\0"
    "nvidia.riva.asr.SpeechRecognitionAlternative"
    "transcript"
    "language_code"
  }},
};

::uint8_t* SpeechRecognitionAlternative::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.SpeechRecognitionAlternative)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // string transcript = 1;
  if (!this->_internal_transcript().empty()) {
    const std::string& _s = this->_internal_transcript();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.SpeechRecognitionAlternative.transcript");
    target = stream->WriteStringMaybeAliased(1, _s, target);
  }

  // float confidence = 2;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = this->_internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        2, this->_internal_confidence(), target);
  }

  // repeated .nvidia.riva.asr.WordInfo words = 3;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_words_size()); i < n; i++) {
    const auto& repfield = this->_internal_words().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(3, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated string language_code = 4;
  for (int i = 0, n = this->_internal_language_code_size(); i < n; ++i) {
    const auto& s = this->_internal_language_code().Get(i);
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.SpeechRecognitionAlternative.language_code");
    target = stream->WriteString(4, s, target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.SpeechRecognitionAlternative)
  return target;
}

::size_t SpeechRecognitionAlternative::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.SpeechRecognitionAlternative)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.WordInfo words = 3;
  total_size += 1UL * this->_internal_words_size();
  for (const auto& msg : this->_internal_words()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // repeated string language_code = 4;
  total_size += 1 * ::google::protobuf::internal::FromIntSize(_internal_language_code().size());
  for (int i = 0, n = _internal_language_code().size(); i < n; ++i) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
        _internal_language_code().Get(i));
  }
  // string transcript = 1;
  if (!this->_internal_transcript().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_transcript());
  }

  // float confidence = 2;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = this->_internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    total_size += 5;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData SpeechRecognitionAlternative::_class_data_ = {
    SpeechRecognitionAlternative::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* SpeechRecognitionAlternative::GetClassData() const {
  return &_class_data_;
}

void SpeechRecognitionAlternative::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionAlternative*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionAlternative&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.SpeechRecognitionAlternative)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_words()->MergeFrom(
      from._internal_words());
  _this->_internal_mutable_language_code()->MergeFrom(from._internal_language_code());
  if (!from._internal_transcript().empty()) {
    _this->_internal_set_transcript(from._internal_transcript());
  }
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = from._internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    _this->_internal_set_confidence(from._internal_confidence());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionAlternative::CopyFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool SpeechRecognitionAlternative::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* SpeechRecognitionAlternative::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void SpeechRecognitionAlternative::InternalSwap(SpeechRecognitionAlternative* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.words_.InternalSwap(&other->_impl_.words_);
  _impl_.language_code_.InternalSwap(&other->_impl_.language_code_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.transcript_, &other->_impl_.transcript_, arena);
        swap(_impl_.confidence_, other->_impl_.confidence_);
}

::google::protobuf::Metadata SpeechRecognitionAlternative::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[14]);
}
// ===================================================================

class WordInfo::_Internal {
 public:
};

WordInfo::WordInfo(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.WordInfo)
}
inline PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : word_(arena, from.word_),
        language_code_(arena, from.language_code_),
        _cached_size_{0} {}

WordInfo::WordInfo(
    ::google::protobuf::Arena* arena,
    const WordInfo& from)
    : ::google::protobuf::Message(arena) {
  WordInfo* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, start_time_),
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::speaker_tag_));

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.WordInfo)
}
inline PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : word_(arena),
        language_code_(arena),
        _cached_size_{0} {}

inline void WordInfo::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           0,
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::speaker_tag_));
}
WordInfo::~WordInfo() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.WordInfo)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void WordInfo::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.word_.Destroy();
  _impl_.language_code_.Destroy();
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void WordInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.WordInfo)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.word_.ClearToEmpty();
  _impl_.language_code_.ClearToEmpty();
  ::memset(&_impl_.start_time_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.speaker_tag_) -
      reinterpret_cast<char*>(&_impl_.start_time_)) + sizeof(_impl_.speaker_tag_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* WordInfo::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 0, 50, 2> WordInfo::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_WordInfo_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // int32 start_time = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(WordInfo, _impl_.start_time_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)}},
    // int32 end_time = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(WordInfo, _impl_.end_time_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_)}},
    // string word = 3;
    {::_pbi::TcParser::FastUS1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_)}},
    // float confidence = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_)}},
    // int32 speaker_tag = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(WordInfo, _impl_.speaker_tag_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)}},
    // string language_code = 6;
    {::_pbi::TcParser::FastUS1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.language_code_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // int32 start_time = 1;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 end_time = 2;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string word = 3;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 4;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // int32 speaker_tag = 5;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string language_code = 6;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.language_code_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\30\0\0\4\0\0\15\0"
    "nvidia.riva.asr.WordInfo"
    "word"
    "language_code"
  }},
};

::uint8_t* WordInfo::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.WordInfo)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // int32 start_time = 1;
  if (this->_internal_start_time() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<1>(
            stream, this->_internal_start_time(), target);
  }

  // int32 end_time = 2;
  if (this->_internal_end_time() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<2>(
            stream, this->_internal_end_time(), target);
  }

  // string word = 3;
  if (!this->_internal_word().empty()) {
    const std::string& _s = this->_internal_word();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.WordInfo.word");
    target = stream->WriteStringMaybeAliased(3, _s, target);
  }

  // float confidence = 4;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = this->_internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        4, this->_internal_confidence(), target);
  }

  // int32 speaker_tag = 5;
  if (this->_internal_speaker_tag() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<5>(
            stream, this->_internal_speaker_tag(), target);
  }

  // string language_code = 6;
  if (!this->_internal_language_code().empty()) {
    const std::string& _s = this->_internal_language_code();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "nvidia.riva.asr.WordInfo.language_code");
    target = stream->WriteStringMaybeAliased(6, _s, target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.WordInfo)
  return target;
}

::size_t WordInfo::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.WordInfo)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string word = 3;
  if (!this->_internal_word().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_word());
  }

  // string language_code = 6;
  if (!this->_internal_language_code().empty()) {
    total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                    this->_internal_language_code());
  }

  // int32 start_time = 1;
  if (this->_internal_start_time() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_start_time());
  }

  // int32 end_time = 2;
  if (this->_internal_end_time() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_end_time());
  }

  // float confidence = 4;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = this->_internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    total_size += 5;
  }

  // int32 speaker_tag = 5;
  if (this->_internal_speaker_tag() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_speaker_tag());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData WordInfo::_class_data_ = {
    WordInfo::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* WordInfo::GetClassData() const {
  return &_class_data_;
}

void WordInfo::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<WordInfo*>(&to_msg);
  auto& from = static_cast<const WordInfo&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.WordInfo)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_word().empty()) {
    _this->_internal_set_word(from._internal_word());
  }
  if (!from._internal_language_code().empty()) {
    _this->_internal_set_language_code(from._internal_language_code());
  }
  if (from._internal_start_time() != 0) {
    _this->_internal_set_start_time(from._internal_start_time());
  }
  if (from._internal_end_time() != 0) {
    _this->_internal_set_end_time(from._internal_end_time());
  }
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_confidence = from._internal_confidence();
  ::uint32_t raw_confidence;
  memcpy(&raw_confidence, &tmp_confidence, sizeof(tmp_confidence));
  if (raw_confidence != 0) {
    _this->_internal_set_confidence(from._internal_confidence());
  }
  if (from._internal_speaker_tag() != 0) {
    _this->_internal_set_speaker_tag(from._internal_speaker_tag());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void WordInfo::CopyFrom(const WordInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.WordInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool WordInfo::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* WordInfo::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void WordInfo::InternalSwap(WordInfo* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.word_, &other->_impl_.word_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)
      + sizeof(WordInfo::_impl_.speaker_tag_)
      - PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)>(
          reinterpret_cast<char*>(&_impl_.start_time_),
          reinterpret_cast<char*>(&other->_impl_.start_time_));
}

::google::protobuf::Metadata WordInfo::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[15]);
}
// ===================================================================

class StreamingRecognizeResponse::_Internal {
 public:
  using HasBits = decltype(std::declval<StreamingRecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_);
  static const ::nvidia::riva::RequestId& id(const StreamingRecognizeResponse* msg);
  static void set_has_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

const ::nvidia::riva::RequestId& StreamingRecognizeResponse::_Internal::id(const StreamingRecognizeResponse* msg) {
  return *msg->_impl_.id_;
}
void StreamingRecognizeResponse::clear_id() {
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  if (_impl_.id_ != nullptr) _impl_.id_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
StreamingRecognizeResponse::StreamingRecognizeResponse(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.StreamingRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

StreamingRecognizeResponse::StreamingRecognizeResponse(
    ::google::protobuf::Arena* arena,
    const StreamingRecognizeResponse& from)
    : ::google::protobuf::Message(arena) {
  StreamingRecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.id_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::RequestId>(arena, *from._impl_.id_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.StreamingRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void StreamingRecognizeResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.id_ = {};
}
StreamingRecognizeResponse::~StreamingRecognizeResponse() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.StreamingRecognizeResponse)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void StreamingRecognizeResponse::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  delete _impl_.id_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void StreamingRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.StreamingRecognizeResponse)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.id_ != nullptr);
    _impl_.id_->Clear();
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* StreamingRecognizeResponse::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 7> StreamingRecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    100, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_StreamingRecognizeResponse_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // .nvidia.riva.RequestId id = 100;
    {::_pbi::TcParser::FastMtS2,
     {1698, 0, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.id_)}},
    // repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_)}},
  }}, {{
    100, 0, 1,
    65534, 1,
    65535, 65535
  }}, {{
    // repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .nvidia.riva.RequestId id = 100;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.id_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::StreamingRecognitionResult>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::RequestId>()},
  }}, {{
  }},
};

::uint8_t* StreamingRecognizeResponse::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.StreamingRecognizeResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_results_size()); i < n; i++) {
    const auto& repfield = this->_internal_results().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  cached_has_bits = _impl_._has_bits_[0];
  // .nvidia.riva.RequestId id = 100;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        100, _Internal::id(this),
        _Internal::id(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.StreamingRecognizeResponse)
  return target;
}

::size_t StreamingRecognizeResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.StreamingRecognizeResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;
  total_size += 1UL * this->_internal_results_size();
  for (const auto& msg : this->_internal_results()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // .nvidia.riva.RequestId id = 100;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size +=
        2 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.id_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData StreamingRecognizeResponse::_class_data_ = {
    StreamingRecognizeResponse::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* StreamingRecognizeResponse::GetClassData() const {
  return &_class_data_;
}

void StreamingRecognizeResponse::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeResponse*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeResponse&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.StreamingRecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  if ((from._impl_._has_bits_[0] & 0x00000001u) != 0) {
    _this->_internal_mutable_id()->::nvidia::riva::RequestId::MergeFrom(
        from._internal_id());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeResponse::CopyFrom(const StreamingRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.StreamingRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool StreamingRecognizeResponse::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* StreamingRecognizeResponse::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void StreamingRecognizeResponse::InternalSwap(StreamingRecognizeResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  swap(_impl_.id_, other->_impl_.id_);
}

::google::protobuf::Metadata StreamingRecognizeResponse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[16]);
}
// ===================================================================

class PipelineStates::_Internal {
 public:
};

PipelineStates::PipelineStates(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.PipelineStates)
}
inline PROTOBUF_NDEBUG_INLINE PipelineStates::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : vad_probabilities_{visibility, arena, from.vad_probabilities_},
        _cached_size_{0} {}

PipelineStates::PipelineStates(
    ::google::protobuf::Arena* arena,
    const PipelineStates& from)
    : ::google::protobuf::Message(arena) {
  PipelineStates* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.PipelineStates)
}
inline PROTOBUF_NDEBUG_INLINE PipelineStates::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : vad_probabilities_{visibility, arena},
        _cached_size_{0} {}

inline void PipelineStates::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
PipelineStates::~PipelineStates() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.PipelineStates)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void PipelineStates::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void PipelineStates::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.PipelineStates)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.vad_probabilities_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* PipelineStates::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 0, 0, 2> PipelineStates::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_PipelineStates_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    // repeated float vad_probabilities = 1;
    {::_pbi::TcParser::FastF32P1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(PipelineStates, _impl_.vad_probabilities_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated float vad_probabilities = 1;
    {PROTOBUF_FIELD_OFFSET(PipelineStates, _impl_.vad_probabilities_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedFloat)},
  }},
  // no aux_entries
  {{
  }},
};

::uint8_t* PipelineStates::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.PipelineStates)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated float vad_probabilities = 1;
  if (this->_internal_vad_probabilities_size() > 0) {
    target = stream->WriteFixedPacked(1, _internal_vad_probabilities(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.PipelineStates)
  return target;
}

::size_t PipelineStates::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.PipelineStates)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated float vad_probabilities = 1;
  {
    std::size_t data_size = std::size_t{4} *
        ::_pbi::FromIntSize(this->_internal_vad_probabilities_size())
    ;
    std::size_t tag_size = data_size == 0
        ? 0
        : 1 + ::_pbi::WireFormatLite::Int32Size(
                            static_cast<int32_t>(data_size))
    ;
    total_size += tag_size + data_size;
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData PipelineStates::_class_data_ = {
    PipelineStates::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* PipelineStates::GetClassData() const {
  return &_class_data_;
}

void PipelineStates::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<PipelineStates*>(&to_msg);
  auto& from = static_cast<const PipelineStates&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.PipelineStates)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_vad_probabilities()->MergeFrom(from._internal_vad_probabilities());
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void PipelineStates::CopyFrom(const PipelineStates& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.PipelineStates)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool PipelineStates::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* PipelineStates::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void PipelineStates::InternalSwap(PipelineStates* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.vad_probabilities_.InternalSwap(&other->_impl_.vad_probabilities_);
}

::google::protobuf::Metadata PipelineStates::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[17]);
}
// ===================================================================

class StreamingRecognitionResult::_Internal {
 public:
  using HasBits = decltype(std::declval<StreamingRecognitionResult>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
    8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_);
  static const ::nvidia::riva::asr::PipelineStates& pipeline_states(const StreamingRecognitionResult* msg);
  static void set_has_pipeline_states(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

const ::nvidia::riva::asr::PipelineStates& StreamingRecognitionResult::_Internal::pipeline_states(const StreamingRecognitionResult* msg) {
  return *msg->_impl_.pipeline_states_;
}
StreamingRecognitionResult::StreamingRecognitionResult(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:nvidia.riva.asr.StreamingRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        alternatives_{visibility, arena, from.alternatives_} {}

StreamingRecognitionResult::StreamingRecognitionResult(
    ::google::protobuf::Arena* arena,
    const StreamingRecognitionResult& from)
    : ::google::protobuf::Message(arena) {
  StreamingRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.pipeline_states_ = (cached_has_bits & 0x00000001u)
                ? CreateMaybeMessage<::nvidia::riva::asr::PipelineStates>(arena, *from._impl_.pipeline_states_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, is_final_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, is_final_),
           offsetof(Impl_, audio_processed_) -
               offsetof(Impl_, is_final_) +
               sizeof(Impl_::audio_processed_));

  // @@protoc_insertion_point(copy_constructor:nvidia.riva.asr.StreamingRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        alternatives_{visibility, arena} {}

inline void StreamingRecognitionResult::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, pipeline_states_),
           0,
           offsetof(Impl_, audio_processed_) -
               offsetof(Impl_, pipeline_states_) +
               sizeof(Impl_::audio_processed_));
}
StreamingRecognitionResult::~StreamingRecognitionResult() {
  // @@protoc_insertion_point(destructor:nvidia.riva.asr.StreamingRecognitionResult)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void StreamingRecognitionResult::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  delete _impl_.pipeline_states_;
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void StreamingRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.riva.asr.StreamingRecognitionResult)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.pipeline_states_ != nullptr);
    _impl_.pipeline_states_->Clear();
  }
  ::memset(&_impl_.is_final_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.audio_processed_) -
      reinterpret_cast<char*>(&_impl_.is_final_)) + sizeof(_impl_.audio_processed_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* StreamingRecognitionResult::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 2, 0, 2> StreamingRecognitionResult::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_),
    0, // no _extensions_
    7, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967176,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    &_StreamingRecognitionResult_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_)}},
    // bool is_final = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionResult, _impl_.is_final_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_)}},
    // float stability = 3;
    {::_pbi::TcParser::FastF32S1,
     {29, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // int32 channel_tag = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(StreamingRecognitionResult, _impl_.channel_tag_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_)}},
    // float audio_processed = 6;
    {::_pbi::TcParser::FastF32S1,
     {53, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.audio_processed_)}},
    // optional .nvidia.riva.asr.PipelineStates pipeline_states = 7;
    {::_pbi::TcParser::FastMtS1,
     {58, 0, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.pipeline_states_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool is_final = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // float stability = 3;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // int32 channel_tag = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // float audio_processed = 6;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.audio_processed_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // optional .nvidia.riva.asr.PipelineStates pipeline_states = 7;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.pipeline_states_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::SpeechRecognitionAlternative>()},
    {::_pbi::TcParser::GetTable<::nvidia::riva::asr::PipelineStates>()},
  }}, {{
  }},
};

::uint8_t* StreamingRecognitionResult::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.riva.asr.StreamingRecognitionResult)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_alternatives_size()); i < n; i++) {
    const auto& repfield = this->_internal_alternatives().Get(i);
    target = ::google::protobuf::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  // bool is_final = 2;
  if (this->_internal_is_final() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(
        2, this->_internal_is_final(), target);
  }

  // float stability = 3;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_stability = this->_internal_stability();
  ::uint32_t raw_stability;
  memcpy(&raw_stability, &tmp_stability, sizeof(tmp_stability));
  if (raw_stability != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        3, this->_internal_stability(), target);
  }

  // int32 channel_tag = 5;
  if (this->_internal_channel_tag() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::
        WriteInt32ToArrayWithField<5>(
            stream, this->_internal_channel_tag(), target);
  }

  // float audio_processed = 6;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = this->_internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(
        6, this->_internal_audio_processed(), target);
  }

  cached_has_bits = _impl_._has_bits_[0];
  // optional .nvidia.riva.asr.PipelineStates pipeline_states = 7;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        7, _Internal::pipeline_states(this),
        _Internal::pipeline_states(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.riva.asr.StreamingRecognitionResult)
  return target;
}

::size_t StreamingRecognitionResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.riva.asr.StreamingRecognitionResult)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;
  total_size += 1UL * this->_internal_alternatives_size();
  for (const auto& msg : this->_internal_alternatives()) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
  }
  // optional .nvidia.riva.asr.PipelineStates pipeline_states = 7;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size +=
        1 + ::google::protobuf::internal::WireFormatLite::MessageSize(*_impl_.pipeline_states_);
  }

  // bool is_final = 2;
  if (this->_internal_is_final() != 0) {
    total_size += 2;
  }

  // float stability = 3;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_stability = this->_internal_stability();
  ::uint32_t raw_stability;
  memcpy(&raw_stability, &tmp_stability, sizeof(tmp_stability));
  if (raw_stability != 0) {
    total_size += 5;
  }

  // int32 channel_tag = 5;
  if (this->_internal_channel_tag() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
        this->_internal_channel_tag());
  }

  // float audio_processed = 6;
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = this->_internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    total_size += 5;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData StreamingRecognitionResult::_class_data_ = {
    StreamingRecognitionResult::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* StreamingRecognitionResult::GetClassData() const {
  return &_class_data_;
}

void StreamingRecognitionResult::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionResult*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionResult&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:nvidia.riva.asr.StreamingRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  if ((from._impl_._has_bits_[0] & 0x00000001u) != 0) {
    _this->_internal_mutable_pipeline_states()->::nvidia::riva::asr::PipelineStates::MergeFrom(
        from._internal_pipeline_states());
  }
  if (from._internal_is_final() != 0) {
    _this->_internal_set_is_final(from._internal_is_final());
  }
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_stability = from._internal_stability();
  ::uint32_t raw_stability;
  memcpy(&raw_stability, &tmp_stability, sizeof(tmp_stability));
  if (raw_stability != 0) {
    _this->_internal_set_stability(from._internal_stability());
  }
  if (from._internal_channel_tag() != 0) {
    _this->_internal_set_channel_tag(from._internal_channel_tag());
  }
  static_assert(sizeof(::uint32_t) == sizeof(float),
                "Code assumes ::uint32_t and float are the same size.");
  float tmp_audio_processed = from._internal_audio_processed();
  ::uint32_t raw_audio_processed;
  memcpy(&raw_audio_processed, &tmp_audio_processed, sizeof(tmp_audio_processed));
  if (raw_audio_processed != 0) {
    _this->_internal_set_audio_processed(from._internal_audio_processed());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionResult::CopyFrom(const StreamingRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.riva.asr.StreamingRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool StreamingRecognitionResult::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* StreamingRecognitionResult::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void StreamingRecognitionResult::InternalSwap(StreamingRecognitionResult* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.audio_processed_)
      + sizeof(StreamingRecognitionResult::_impl_.audio_processed_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.pipeline_states_)>(
          reinterpret_cast<char*>(&_impl_.pipeline_states_),
          reinterpret_cast<char*>(&other->_impl_.pipeline_states_));
}

::google::protobuf::Metadata StreamingRecognitionResult::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_getter, &descriptor_table_riva_2fproto_2friva_5fasr_2eproto_once,
      file_level_metadata_riva_2fproto_2friva_5fasr_2eproto[18]);
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace asr
}  // namespace riva
}  // namespace nvidia
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
#include "google/protobuf/port_undef.inc"
